{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GATConv, SimpleConv\n",
    "from torch_geometric.transforms import Constant\n",
    "import pickle\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") # Set device (use GPU if available)\n",
    "filename = 'records1.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_memo(memo, filename = filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(memo, f)\n",
    "\n",
    "def load_memo(filename = filename):\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            memo = pickle.load(f)\n",
    "            return memo\n",
    "    except FileNotFoundError:\n",
    "        print(\"Memo file not found. Returning an empty dictionary.\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memo file not found. Returning an empty dictionary.\n"
     ]
    }
   ],
   "source": [
    "Memo = load_memo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGraphDataset(Dataset):\n",
    "    def __init__(self, root, split='train', transform=None):\n",
    "         # Initialize the dataset with the root directory, split, and optional transform\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.graph_files = []\n",
    "\n",
    "        classes = os.listdir(root) # Get the list of classes (subdirectories) in the root directory\n",
    "\n",
    "        # Iterate through each class\n",
    "        for class_folder in classes:\n",
    "            class_path = os.path.join(root, class_folder)\n",
    "            \n",
    "            # Check if the class folder is a directory\n",
    "            if os.path.isdir(class_path):\n",
    "                # Create the path to the split folder (train, test, etc.) within the class folder\n",
    "                split_folder = os.path.join(class_path, split)\n",
    "                \n",
    "                # Get the list of graph files (with the .gph extension) in the split folder\n",
    "                graph_files = [os.path.join(split_folder, f) for f in os.listdir(split_folder) if f.endswith('.gph')]\n",
    "                \n",
    "                # Extend the list of graph files in the dataset with the current class's graph files\n",
    "                self.graph_files.extend(graph_files)\n",
    "\n",
    "    def __len__(self): # Return the total number of graph files in the dataset\n",
    "        return len(self.graph_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the file path of the graph file at the specified index\n",
    "        graph_file = self.graph_files[idx]\n",
    "        \n",
    "        # Load the graph data from the file using torch\n",
    "        data = torch.load(graph_file)\n",
    "        \n",
    "        # Add ground truth label based on class (assuming class names in the file paths)\n",
    "        class_label = None\n",
    "        for i, class_name in enumerate(['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night', 'sofa', 'table', 'toilet']):\n",
    "            if class_name in graph_file:\n",
    "                class_label = i\n",
    "                break\n",
    "\n",
    "        # Check if class_label is still None, indicating an unknown class\n",
    "        if class_label is None:\n",
    "            raise ValueError(f\"Unknown class for file: {graph_file}\")\n",
    "\n",
    "        # Set the ground truth label as a tensor in the 'y' attribute of the graph data\n",
    "        data.y = torch.tensor([class_label], dtype=torch.long)\n",
    "\n",
    "        # Apply the transform if provided\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# Load the graph data using the CustomGraphDataset\n",
    "def load_graph_data(filepath):\n",
    "    dataset = CustomGraphDataset(filepath, transform=None)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 10\n",
    "mutation_rate = 0.2\n",
    "tournament_size = 4\n",
    "num_gens = 40\n",
    "root_path = '3DGraphz7'\n",
    "\n",
    "hyperparameters = {\n",
    "    \"learning_rate\": [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    \"batch_size\": [4, 8, 16, 32, 64, 128],\n",
    "    \"layer_type\": [GCNConv, GATConv],  # The type of GNN layers to use\n",
    "    \"hidden\": [0, 4, 8, 16, 32, 64, 128],  # The number of hidden units in each layer\n",
    "    \"weight_decay\": [1e-5, 5e-4, 1e-3],  # The rate at which weights decay for regularization\n",
    "    \"activation\": [torch.relu, torch.tanh, torch.sigmoid],  # The activation function to use in the hidden layers\n",
    "    \"pooling\": [global_add_pool, global_mean_pool, global_max_pool],\n",
    "    \"epochs\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "}\n",
    "\n",
    "Encoding = [\"layer_type\", \"hidden\", \"hidden\", \"hidden\", \"hidden\", \"activation\", \"pooling\", \"learning_rate\", \"batch_size\", \"weight_decay\", \"epochs\"]\n",
    "Range_of_parameters = [len(hyperparameters[y]) for y in Encoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(n, m):\n",
    "    permutations_list = []\n",
    "    while len(permutations_list) < n:\n",
    "        permutation = []\n",
    "        for i in range(m):\n",
    "            permutation.append(random.choice(range(Range_of_parameters[i])))\n",
    "        if permutation not in permutations_list:\n",
    "            permutations_list.append(permutation)\n",
    "    return permutations_list\n",
    "\n",
    "def n_crossover(parent1, parent2):\n",
    "    offspring1 = parent1.copy()\n",
    "    offspring2 = parent2.copy()\n",
    "    for i in range(len(parent1)):\n",
    "        if i % 2 == 0:\n",
    "            offspring1[i] = parent1[i]\n",
    "            offspring2[i] = parent2[i]\n",
    "        else:\n",
    "            offspring1[i] = parent2[i]\n",
    "            offspring2[i] = parent1[i]\n",
    "    return [offspring1, offspring2]\n",
    "\n",
    "def mutate(person, perc):\n",
    "    mutated_person = person.copy()\n",
    "    while random.random() < perc:\n",
    "        i = random.randint(0,len(mutated_person) - 1)\n",
    "        inc = random.choice([1, -1])\n",
    "        mutated_person[i] = (mutated_person[i] + inc) % Range_of_parameters[i]\n",
    "    return mutated_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_based_selection(population,fitness_function ,crossover_function, mutation_function, mutation_rate, allow_parents = True):\n",
    "    fitness_values = [fitness_function(individual) for individual in population]\n",
    "    new_population = []\n",
    "    \n",
    "    if allow_parents == True:\n",
    "        new_population = population.copy()\n",
    "    \n",
    "    for i in range(len(population)):\n",
    "        offsprings = []\n",
    "        index = 0\n",
    "        print(offsprings)\n",
    "        while(len(offsprings) < 2):\n",
    "            parent1 = random.choices(population, weights=fitness_values)[0]\n",
    "            parent2 = random.choices(population, weights=fitness_values)[0]\n",
    "\n",
    "            offsprings = crossover_function(parent1, parent2)\n",
    "            index += 1\n",
    "            if index >=100:\n",
    "                break\n",
    "        for offspring in offsprings:\n",
    "            new_population += [mutation_function(offspring, mutation_rate)]\n",
    "        \n",
    "    return new_population\n",
    "\n",
    "def ranked_based_selection(population, fitness_function, crossover_function, mutation_function, mutation_rate, allow_parents=True):\n",
    "    sorted_population = sorted(population, key=lambda x: fitness_function(x))\n",
    "    population_size = len(population)\n",
    "\n",
    "    selection_weights = [i for i in range(1, population_size + 1)]\n",
    "    \n",
    "    new_population = []\n",
    "    if allow_parents:\n",
    "        new_population = sorted_population.copy()\n",
    "    \n",
    "    for i in range(len(population)):\n",
    "        \n",
    "        offsprings = []\n",
    "        index = 0\n",
    "        while(len(offsprings) < 2):\n",
    "            parent1 = random.choices(sorted_population, weights=selection_weights)[0]\n",
    "            parent2 = random.choices(sorted_population, weights=selection_weights)[0]\n",
    "\n",
    "            offsprings = crossover_function(parent1, parent2)\n",
    "            index += 1\n",
    "            if index >=100:\n",
    "                break\n",
    "        for offspring in offsprings:\n",
    "            new_population += [mutation_function(offspring, mutation_rate)]\n",
    "        \n",
    "    return new_population\n",
    "\n",
    "def tournament_ranked_based_selection(population,fitness_function, crossover_function, mutation_function, mutation_rate, tournament_size=2, allow_parents=True):\n",
    "    new_population = []\n",
    "\n",
    "    if allow_parents:\n",
    "        new_population = population.copy()\n",
    "   \n",
    "    for i in range(len(population)):\n",
    "\n",
    "        offsprings = []\n",
    "        index = 0\n",
    "        while(len(offsprings) < 2):\n",
    "            tournament_individuals = random.sample(population, tournament_size)\n",
    "            sorted_tournament = sorted(tournament_individuals, key=lambda x: fitness_function(x))\n",
    "\n",
    "            \n",
    "            selection_weights = [i for i in range(1, tournament_size + 1)]\n",
    "\n",
    "            parent1 = random.choices(sorted_tournament, weights=selection_weights)[0]\n",
    "            parent2 = random.choices(sorted_tournament, weights=selection_weights)[0]\n",
    "\n",
    "            offsprings = crossover_function(parent1, parent2)\n",
    "            index += 1\n",
    "            if index >=100:\n",
    "                break\n",
    "        \n",
    "        for offspring in offsprings:\n",
    "            new_population += [mutation_function(offspring, mutation_rate)]\n",
    "        \n",
    "    \n",
    "    return new_population\n",
    "\n",
    "def tournament_fitness_based_selection(population,fitness_function, crossover_function, mutation_function, mutation_rate, allow_parents=True):\n",
    "    new_population = []\n",
    "    if allow_parents:\n",
    "        new_population = population.copy()\n",
    "    \n",
    "    for i in range(len(population)):\n",
    "        offsprings = []\n",
    "        index = 0\n",
    "        while(len(offsprings) < 2):\n",
    "            tournament_individuals = random.sample(population, tournament_size)\n",
    "            tournament_fitness_values = [fitness_function(individual) for individual in tournament_individuals]\n",
    "            \n",
    "            parent1 = random.choices(tournament_individuals, weights=tournament_fitness_values)[0]\n",
    "            parent2 = random.choices(tournament_individuals, weights=tournament_fitness_values)[0]\n",
    "\n",
    "            offsprings = crossover_function(parent1, parent2)\n",
    "            index += 1\n",
    "            if index >=100:\n",
    "                break\n",
    "\n",
    "        for offspring in offsprings:\n",
    "            new_population += [mutation_function(offspring, mutation_rate)]\n",
    "        \n",
    "    return new_population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argsort(seq):\n",
    "    return sorted(range(len(seq)), key=seq.__getitem__)[::-1]\n",
    "\n",
    "def truncation(population,fitness_function, npop):\n",
    "    fitness_values = [fitness_function(individual) for individual in population]\n",
    "    indexes = argsort(fitness_values)[:npop]\n",
    "    selected_population = [population[index] for index in indexes]\n",
    "    return selected_population\n",
    "\n",
    "def binary_tournament(population,fitness_function, npop):\n",
    "    retained_population = []\n",
    "    while len(retained_population) < npop:\n",
    "        ind1, ind2 = random.sample(population, 2)\n",
    "        winner = ind1 if fitness_function(ind1) > fitness_function(ind2) else ind2\n",
    "        retained_population.append(winner)\n",
    "    \n",
    "    return retained_population\n",
    "\n",
    "def genetic_algorithm(population, fitness_function, parent_selection_function = fitness_based_selection, survival_function = truncation, crossover_function = n_crossover, mutation_function = mutate, mutation_rate = 0.2, allow_parents = True):\n",
    "    new_population = parent_selection_function(population, fitness_function, crossover_function, mutation_function, mutation_rate, allow_parents)\n",
    "    return survival_function(new_population, fitness_function, len(population))\n",
    "\n",
    "def genetic_algorithm_n_gens(population,fitness_function, parent_selection_function = fitness_based_selection, survival_function = truncation, crossover_function = n_crossover, mutation_function = mutate, mutation_rate = 0.2, allow_parents = True,n_gens = num_gens, plot = True, display_last_gen = True):\n",
    "    \n",
    "    n = len(population)\n",
    "    \n",
    "    fitness_scores = [fitness_function(individual) for individual in population]\n",
    "    best_scores = [sorted(fitness_scores)[-1]]\n",
    "    average_scores = [sum(fitness_scores) / len(fitness_scores)]\n",
    "    \n",
    "    new_population = population.copy()\n",
    "    \n",
    "    title = f'{parent_selection_function.__name__} + {survival_function.__name__}'\n",
    "    for i in range(n_gens):\n",
    "        print(f\"Gen {i}: \")\n",
    "        new_population = parent_selection_function(new_population, fitness_function, crossover_function, mutation_function, mutation_rate, allow_parents)\n",
    "        new_population = survival_function(new_population, fitness_function, n)\n",
    "        fitness_scores = [fitness_function(individual) for individual in new_population]\n",
    "        best_scores += [sorted(fitness_scores)[-1]]\n",
    "        average_scores += [sum(fitness_scores) / len(fitness_scores) ]\n",
    "    \n",
    "    if plot == True:\n",
    "        # Plotting the data\n",
    "\n",
    "\n",
    "        plt.plot(best_scores, color='blue', label='Best Score')\n",
    "        plt.plot(average_scores, color='red', label='Average Score')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        plt.title(f'Optimizing {fitness_function.__name__} with {parent_selection_function.__name__} + {survival_function.__name__}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    if display_last_gen == True:\n",
    "        print(f'Generation: {n_gens} with {parent_selection_function.__name__} and {survival_function.__name__}')\n",
    "        for i in range(population_size):\n",
    "            print(f'{i+1}. Path = {new_population[i]}, Score = {fitness_function(new_population[i]):.4f}')\n",
    "    save_memo(Memo, filename)\n",
    "    return title, best_scores, average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModelEA0(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = [16], activation_func = torch.relu, layer = GCNConv, pooling = global_mean_pool):\n",
    "        super(GNNModelEA0, self).__init__()\n",
    "        # Graph convolutional layers\n",
    "        self.first = layer(input_dim, output_dim)\n",
    "\n",
    "        self.activation_func = activation_func\n",
    "        self.pooling = pooling\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Apply the first graph convolutional layer followed by ReLU activation\n",
    "        x = self.first(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        # Global mean pooling over the nodes in each graph in the batch\n",
    "        x = self.pooling(x, batch)\n",
    "\n",
    "        # Apply log_softmax for classification\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "\n",
    "class GNNModelEA1(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = [16], activation_func = torch.relu, layer = GCNConv, pooling = global_mean_pool):\n",
    "        super(GNNModelEA1, self).__init__()\n",
    "        # Graph convolutional layers\n",
    "        self.first = layer(input_dim, hidden_dim[0])\n",
    "        self.hidden = None\n",
    "        self.out = layer(hidden_dim[0], output_dim)\n",
    "\n",
    "        self.activation_func = activation_func\n",
    "        self.pooling = pooling\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Apply the first graph convolutional layer followed by ReLU activation\n",
    "        x = self.first(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        # Apply the third graph convolutional layer\n",
    "        x = self.out(x, edge_index)\n",
    "\n",
    "        # Global mean pooling over the nodes in each graph in the batch\n",
    "        x = self.pooling(x, batch)\n",
    "\n",
    "        # Apply log_softmax for classification\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "    \n",
    "class GNNModelEA2(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = [16, 16], activation_func = torch.relu, layer = GCNConv, pooling = global_mean_pool):\n",
    "        super(GNNModelEA2, self).__init__()\n",
    "        # Graph convolutional layers\n",
    "        self.first = layer(input_dim, hidden_dim[0])\n",
    "        self.hidden = layer(hidden_dim[0], hidden_dim[1])\n",
    "        self.out = layer(hidden_dim[1], output_dim)\n",
    "\n",
    "        self.activation_func = activation_func\n",
    "        self.pooling = pooling\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Apply the first graph convolutional layer followed by ReLU activation\n",
    "        x = self.first(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        # Apply the second graph convolutional layer followed by ReLU activation\n",
    "        x = self.hidden(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        # Apply the third graph convolutional layer\n",
    "        x = self.out(x, edge_index)\n",
    "\n",
    "        # Global mean pooling over the nodes in each graph in the batch\n",
    "        x = self.pooling(x, batch)\n",
    "\n",
    "        # Apply log_softmax for classification\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "\n",
    "class GNNModelEA3(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = [16, 16, 16], activation_func = torch.relu, layer = GCNConv, pooling = global_mean_pool):\n",
    "        super(GNNModelEA3, self).__init__()\n",
    "        # Graph convolutional layers\n",
    "        self.first = layer(input_dim, hidden_dim[0])\n",
    "        self.hidden = layer(hidden_dim[0], hidden_dim[1])\n",
    "        self.hidden2 = layer(hidden_dim[1], hidden_dim[2])\n",
    "        self.out = layer(hidden_dim[2], output_dim)\n",
    "\n",
    "        self.activation_func = activation_func\n",
    "        self.pooling = pooling\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Apply the first graph convolutional layer followed by ReLU activation\n",
    "        x = self.first(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        # Apply the second graph convolutional layer followed by ReLU activation\n",
    "        x = self.hidden(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        x = self.hidden2(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        # Apply the third graph convolutional layer\n",
    "        x = self.out(x, edge_index)\n",
    "\n",
    "        # Global mean pooling over the nodes in each graph in the batch\n",
    "        x = self.pooling(x, batch)\n",
    "\n",
    "        # Apply log_softmax for classification\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "    \n",
    "class GNNModelEA4(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = [16, 16, 16, 16], activation_func = torch.relu, layer = GCNConv, pooling = global_mean_pool):\n",
    "        super(GNNModelEA4, self).__init__()\n",
    "        # Graph convolutional layers\n",
    "        self.first = layer(input_dim, hidden_dim[0])\n",
    "        self.hidden = layer(hidden_dim[0], hidden_dim[1])\n",
    "        self.hidden2 = layer(hidden_dim[1], hidden_dim[2])\n",
    "        self.hidden3 = layer(hidden_dim[2], hidden_dim[3])\n",
    "        self.out = layer(hidden_dim[3], output_dim)\n",
    "\n",
    "        self.activation_func = activation_func\n",
    "        self.pooling = pooling\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Apply the first graph convolutional layer followed by ReLU activation\n",
    "        x = self.first(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        # Apply the second graph convolutional layer followed by ReLU activation\n",
    "        x = self.hidden(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        x = self.hidden2(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        x = self.hidden3(x, edge_index)\n",
    "        x = self.activation_func(x)\n",
    "\n",
    "        # Apply the third graph convolutional layer\n",
    "        x = self.out(x, edge_index)\n",
    "\n",
    "        # Global mean pooling over the nodes in each graph in the batch\n",
    "        x = self.pooling(x, batch)\n",
    "\n",
    "        # Apply log_softmax for classification\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "\n",
    "# Train the GNN model\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted = output.max(1)\n",
    "        total_train += data.y.size(0)\n",
    "        correct_train += predicted.eq(data.y).sum().item()\n",
    "\n",
    "    accuracy_train = correct_train / total_train\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    return accuracy_train, average_loss\n",
    "\n",
    "# Evaluate the GNN model\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_eval = 0\n",
    "    total_eval = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device) \n",
    "            output = model(data)\n",
    "            loss = criterion(output, data.y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = output.max(1)\n",
    "            total_eval += data.y.size(0)\n",
    "            correct_eval += predicted.eq(data.y).sum().item()\n",
    "\n",
    "    accuracy_eval = correct_eval / total_eval\n",
    "    average_loss = total_loss / len(loader)\n",
    "    return accuracy_eval, average_loss\n",
    "\n",
    "# Main function to train and evaluate the GNN model\n",
    "def fitness_function(person, epochs = 20):\n",
    "    person = tuple(person)\n",
    "    if Memo.get(person):\n",
    "        return Memo[person]\n",
    "\n",
    "    layer_type = hyperparameters[Encoding[0]][person[0]]\n",
    "    hidden_dim = [hyperparameters[Encoding[1]][person[1]], hyperparameters[Encoding[2]][person[2]], hyperparameters[Encoding[3]][person[3]], hyperparameters[Encoding[4]][person[4]]]\n",
    "    models = [GNNModelEA0, GNNModelEA1, GNNModelEA2, GNNModelEA3, GNNModelEA4]\n",
    "    for i in range(len(hidden_dim)):\n",
    "        if hidden_dim[i] == 0:\n",
    "            break\n",
    "    GNNmodel = models[i]\n",
    "    activation_func = hyperparameters[Encoding[5]][person[5]]\n",
    "    pooling = hyperparameters[Encoding[6]][person[6]]\n",
    "    lr = hyperparameters[Encoding[7]][person[7]]\n",
    "    batch_size = hyperparameters[Encoding[8]][person[8]]\n",
    "    weight_decay = hyperparameters[Encoding[9]][person[9]]\n",
    "    epochs = hyperparameters[Encoding[10]][person[10]]\n",
    "    \n",
    "    print(\"Layer Type:\", layer_type.__name__)\n",
    "    print(\"Hidden Dimensions:\", hidden_dim)\n",
    "    print(\"Activation Function:\", activation_func.__name__)\n",
    "    print(\"Pooling Function:\", pooling.__name__)\n",
    "    print(\"Learning Rate:\", lr)\n",
    "    print(\"Batch Size:\", batch_size)\n",
    "    print(\"Weight Decay:\", weight_decay)\n",
    "    print(\"Epochs:\", epochs)\n",
    "    \n",
    "    # Define the output path for saving the trained model\n",
    "    output_path = 'Saved/' + root_path + '/'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    output_path += 'model.pt'\n",
    "\n",
    "\n",
    "    # Create training and testing datasets\n",
    "    train_dataset = CustomGraphDataset(root_path, split='train')\n",
    "    test_dataset = CustomGraphDataset(root_path, split='test')\n",
    "    # Define GNN model\n",
    "    input_dim = 7\n",
    "    output_dim = 10\n",
    "    model = GNNmodel(input_dim, output_dim, hidden_dim=hidden_dim, activation_func=activation_func, layer=layer_type, pooling=pooling).to(device)\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Evaluate the model before training and print initial results\n",
    "    test_acc, test_loss = evaluate(model, test_loader, criterion, device)\n",
    "    print(f'Epoch {0}/{epochs} => 'f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "    # Lists to store results for plotting\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Train the model and capture results\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_acc, train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        test_acc, test_loss = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        train_accuracies.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}/{epochs} => '\n",
    "                  f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f} | '\n",
    "                  f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "    Memo[person] = test_accuracies[-1]\n",
    "    # Save the trained model\n",
    "    #model.save_model(output_path)\n",
    "    return test_accuracies[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gene_details(index, person):\n",
    "\n",
    "    layer_type = hyperparameters[Encoding[0]][person[0]]\n",
    "    hidden_dims = [hyperparameters[Encoding[1]][person[1]], hyperparameters[Encoding[2]][person[2]], hyperparameters[Encoding[3]][person[3]], hyperparameters[Encoding[4]][person[4]]]\n",
    "    activation_func = hyperparameters[Encoding[5]][person[5]]\n",
    "    pooling = hyperparameters[Encoding[6]][person[6]]\n",
    "    lr = hyperparameters[Encoding[7]][person[7]]\n",
    "    batch_size = hyperparameters[Encoding[8]][person[8]]\n",
    "    weight_decay = hyperparameters[Encoding[9]][person[9]]\n",
    "\n",
    "    print(f\"Gene {index} Details:\")\n",
    "    print(\"Layer Type:\", layer_type.__name__)\n",
    "    print(\"Hidden Dimensions:\", hidden_dims)\n",
    "    print(\"Activation Function:\", activation_func.__name__)\n",
    "    print(\"Pooling Function:\", pooling.__name__)\n",
    "    print(\"Learning Rate:\", lr)\n",
    "    print(\"Batch Size:\", batch_size)\n",
    "    print(\"Weight Decay:\", weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = generate_population(10, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene 1: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [128, 32, 128, 16]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 32\n",
      "Weight Decay: 0.001\n",
      "Epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 => Test Loss: 119.9474, Test Accuracy: 0.0810\n",
      "Epoch 10/100 => Train Loss: 9.9158, Train Accuracy: 0.1275 | Test Loss: 9.8431, Test Accuracy: 0.1242\n",
      "Epoch 20/100 => Train Loss: 10.7206, Train Accuracy: 0.1366 | Test Loss: 13.3629, Test Accuracy: 0.1242\n",
      "Epoch 30/100 => Train Loss: 46.1628, Train Accuracy: 0.1300 | Test Loss: 21.1157, Test Accuracy: 0.1020\n",
      "Epoch 40/100 => Train Loss: 9.8350, Train Accuracy: 0.1429 | Test Loss: 8.6597, Test Accuracy: 0.1111\n",
      "Epoch 50/100 => Train Loss: 8.7292, Train Accuracy: 0.1243 | Test Loss: 11.9591, Test Accuracy: 0.1111\n",
      "Epoch 60/100 => Train Loss: 7.3452, Train Accuracy: 0.1332 | Test Loss: 10.9494, Test Accuracy: 0.1203\n",
      "Epoch 70/100 => Train Loss: 10.9267, Train Accuracy: 0.1310 | Test Loss: 21.6932, Test Accuracy: 0.1242\n",
      "Epoch 80/100 => Train Loss: 12.0339, Train Accuracy: 0.1265 | Test Loss: 29.5387, Test Accuracy: 0.1111\n",
      "Epoch 90/100 => Train Loss: 8.8700, Train Accuracy: 0.1234 | Test Loss: 13.8224, Test Accuracy: 0.1007\n",
      "Epoch 100/100 => Train Loss: 7.5121, Train Accuracy: 0.1335 | Test Loss: 17.1527, Test Accuracy: 0.0941\n",
      "Gene 2: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 16, 0, 8]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 4\n",
      "Weight Decay: 0.0005\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 189.3356, Test Accuracy: 0.1216\n",
      "Epoch 10/100 => Train Loss: 4.0832, Train Accuracy: 0.4446 | Test Loss: 2.8181, Test Accuracy: 0.3817\n",
      "Epoch 20/100 => Train Loss: 2.8767, Train Accuracy: 0.6056 | Test Loss: 6.2043, Test Accuracy: 0.4105\n",
      "Epoch 30/100 => Train Loss: 2.9442, Train Accuracy: 0.6115 | Test Loss: 3.3066, Test Accuracy: 0.5686\n",
      "Epoch 40/100 => Train Loss: 2.5265, Train Accuracy: 0.6198 | Test Loss: 3.6838, Test Accuracy: 0.6078\n",
      "Epoch 50/100 => Train Loss: 2.5067, Train Accuracy: 0.6346 | Test Loss: 3.7878, Test Accuracy: 0.5712\n",
      "Epoch 60/100 => Train Loss: 2.2255, Train Accuracy: 0.6172 | Test Loss: 4.4572, Test Accuracy: 0.4484\n",
      "Epoch 70/100 => Train Loss: 2.5995, Train Accuracy: 0.6387 | Test Loss: 6.6893, Test Accuracy: 0.5464\n",
      "Epoch 80/100 => Train Loss: 2.2797, Train Accuracy: 0.6078 | Test Loss: 3.8838, Test Accuracy: 0.6105\n",
      "Epoch 90/100 => Train Loss: 2.5294, Train Accuracy: 0.5891 | Test Loss: 4.2871, Test Accuracy: 0.5059\n",
      "Epoch 100/100 => Train Loss: 1.9216, Train Accuracy: 0.6510 | Test Loss: 4.7281, Test Accuracy: 0.5425\n",
      "Gene 3: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [128, 32, 4, 32]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.001\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 51.8363, Test Accuracy: 0.1020\n",
      "Epoch 10/100 => Train Loss: 4.5899, Train Accuracy: 0.2427 | Test Loss: 2.8888, Test Accuracy: 0.2288\n",
      "Epoch 20/100 => Train Loss: 3.9513, Train Accuracy: 0.3891 | Test Loss: 3.2534, Test Accuracy: 0.3673\n",
      "Epoch 30/100 => Train Loss: 2.8138, Train Accuracy: 0.4793 | Test Loss: 3.9015, Test Accuracy: 0.4732\n",
      "Epoch 40/100 => Train Loss: 3.1003, Train Accuracy: 0.5178 | Test Loss: 4.3321, Test Accuracy: 0.4824\n",
      "Epoch 50/100 => Train Loss: 2.8573, Train Accuracy: 0.6257 | Test Loss: 5.4266, Test Accuracy: 0.5490\n",
      "Epoch 60/100 => Train Loss: 2.9221, Train Accuracy: 0.5794 | Test Loss: 3.8486, Test Accuracy: 0.4745\n",
      "Epoch 70/100 => Train Loss: 2.9671, Train Accuracy: 0.6229 | Test Loss: 4.8402, Test Accuracy: 0.5843\n",
      "Epoch 80/100 => Train Loss: 2.3911, Train Accuracy: 0.6365 | Test Loss: 3.2185, Test Accuracy: 0.5739\n",
      "Epoch 90/100 => Train Loss: 2.2957, Train Accuracy: 0.6485 | Test Loss: 3.2049, Test Accuracy: 0.6131\n",
      "Epoch 100/100 => Train Loss: 2.5695, Train Accuracy: 0.6333 | Test Loss: 6.1028, Test Accuracy: 0.5451\n",
      "Gene 4: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [64, 32, 64, 0]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 128\n",
      "Weight Decay: 0.001\n",
      "Epochs: 40\n",
      "Epoch 0/40 => Test Loss: 129.4095, Test Accuracy: 0.1111\n",
      "Epoch 10/40 => Train Loss: 4.7923, Train Accuracy: 0.2196 | Test Loss: 3.4910, Test Accuracy: 0.1582\n",
      "Epoch 20/40 => Train Loss: 4.5623, Train Accuracy: 0.2849 | Test Loss: 4.7445, Test Accuracy: 0.2824\n",
      "Epoch 30/40 => Train Loss: 5.8673, Train Accuracy: 0.3036 | Test Loss: 6.4565, Test Accuracy: 0.2680\n",
      "Epoch 40/40 => Train Loss: 3.0061, Train Accuracy: 0.4560 | Test Loss: 5.2250, Test Accuracy: 0.3229\n",
      "Gene 5: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [4, 64, 128, 0]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 4\n",
      "Weight Decay: 0.001\n",
      "Epochs: 10\n",
      "Epoch 0/10 => Test Loss: 2.3335, Test Accuracy: 0.0797\n",
      "Epoch 10/10 => Train Loss: 1.9914, Train Accuracy: 0.4086 | Test Loss: 3.2630, Test Accuracy: 0.1739\n",
      "Gene 6: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [128, 128, 32, 32]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 16\n",
      "Weight Decay: 1e-05\n",
      "Epochs: 30\n",
      "Epoch 0/30 => Test Loss: 3742.6628, Test Accuracy: 0.0745\n",
      "Epoch 10/30 => Train Loss: 3.5221, Train Accuracy: 0.1303 | Test Loss: 2.7132, Test Accuracy: 0.1242\n",
      "Epoch 20/30 => Train Loss: 2.9601, Train Accuracy: 0.1297 | Test Loss: 3.3921, Test Accuracy: 0.1242\n",
      "Epoch 30/30 => Train Loss: 3.0547, Train Accuracy: 0.1392 | Test Loss: 3.0511, Test Accuracy: 0.1242\n",
      "Gene 7: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [64, 8, 4, 0]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 4\n",
      "Weight Decay: 1e-05\n",
      "Epochs: 50\n",
      "Epoch 0/50 => Test Loss: 34.0017, Test Accuracy: 0.0967\n",
      "Epoch 10/50 => Train Loss: 81.3920, Train Accuracy: 0.1761 | Test Loss: 152.4825, Test Accuracy: 0.0824\n",
      "Epoch 20/50 => Train Loss: 112.3323, Train Accuracy: 0.1821 | Test Loss: 132.1289, Test Accuracy: 0.1595\n",
      "Epoch 30/50 => Train Loss: 101.7875, Train Accuracy: 0.2531 | Test Loss: 79.5555, Test Accuracy: 0.2431\n",
      "Epoch 40/50 => Train Loss: 105.8899, Train Accuracy: 0.1925 | Test Loss: 140.9731, Test Accuracy: 0.1477\n",
      "Epoch 50/50 => Train Loss: 101.2238, Train Accuracy: 0.2174 | Test Loss: 165.8794, Test Accuracy: 0.1425\n",
      "Gene 8: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [128, 16, 8, 16]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 128\n",
      "Weight Decay: 0.0005\n",
      "Epochs: 80\n",
      "Epoch 0/80 => Test Loss: 4.2630, Test Accuracy: 0.1255\n",
      "Epoch 10/80 => Train Loss: 2.1675, Train Accuracy: 0.2023 | Test Loss: 2.3926, Test Accuracy: 0.0941\n",
      "Epoch 20/80 => Train Loss: 2.1677, Train Accuracy: 0.2023 | Test Loss: 2.3963, Test Accuracy: 0.0941\n",
      "Epoch 30/80 => Train Loss: 2.1685, Train Accuracy: 0.2023 | Test Loss: 2.3963, Test Accuracy: 0.0941\n",
      "Epoch 40/80 => Train Loss: 2.1675, Train Accuracy: 0.2023 | Test Loss: 2.3963, Test Accuracy: 0.0941\n",
      "Epoch 50/80 => Train Loss: 2.1677, Train Accuracy: 0.2023 | Test Loss: 2.3937, Test Accuracy: 0.0941\n",
      "Epoch 60/80 => Train Loss: 2.1691, Train Accuracy: 0.2023 | Test Loss: 2.4051, Test Accuracy: 0.0941\n",
      "Epoch 70/80 => Train Loss: 2.1677, Train Accuracy: 0.2023 | Test Loss: 2.3886, Test Accuracy: 0.0941\n",
      "Epoch 80/80 => Train Loss: 2.1664, Train Accuracy: 0.2023 | Test Loss: 2.3902, Test Accuracy: 0.0941\n",
      "Gene 9: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [64, 0, 8, 8]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.001\n",
      "Epochs: 40\n",
      "Epoch 0/40 => Test Loss: 6.9298, Test Accuracy: 0.0758\n",
      "Epoch 10/40 => Train Loss: 117.5973, Train Accuracy: 0.4027 | Test Loss: 137.5059, Test Accuracy: 0.2693\n",
      "Epoch 20/40 => Train Loss: 17.1448, Train Accuracy: 0.4077 | Test Loss: 27.3500, Test Accuracy: 0.3516\n",
      "Epoch 30/40 => Train Loss: 32.1758, Train Accuracy: 0.4172 | Test Loss: 38.7677, Test Accuracy: 0.3425\n",
      "Epoch 40/40 => Train Loss: 11.6353, Train Accuracy: 0.4244 | Test Loss: 15.5215, Test Accuracy: 0.2993\n",
      "Gene 10: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [4, 8, 0, 4]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 16\n",
      "Weight Decay: 1e-05\n",
      "Epochs: 20\n",
      "Epoch 0/20 => Test Loss: 6.5396, Test Accuracy: 0.1111\n",
      "Epoch 10/20 => Train Loss: 1.6547, Train Accuracy: 0.5188 | Test Loss: 1.8828, Test Accuracy: 0.3830\n",
      "Epoch 20/20 => Train Loss: 1.4845, Train Accuracy: 0.5488 | Test Loss: 1.8432, Test Accuracy: 0.5163\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for person in persons:\n",
    "    print(f'Gene {index + 1}: ')\n",
    "    fitness_function(person)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 0: \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [128, 16, 4, 16]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Weight Decay: 0.001\n",
      "Epochs: 80\n",
      "Epoch 0/80 => Test Loss: 2.3627, Test Accuracy: 0.1085\n",
      "Epoch 10/80 => Train Loss: 1.2875, Train Accuracy: 0.5989 | Test Loss: 1.5434, Test Accuracy: 0.4379\n",
      "Epoch 20/80 => Train Loss: 1.0093, Train Accuracy: 0.6450 | Test Loss: 1.2995, Test Accuracy: 0.4719\n",
      "Epoch 30/80 => Train Loss: 0.8703, Train Accuracy: 0.6863 | Test Loss: 1.1960, Test Accuracy: 0.5255\n",
      "Epoch 40/80 => Train Loss: 0.7949, Train Accuracy: 0.7299 | Test Loss: 1.0859, Test Accuracy: 0.5791\n",
      "Epoch 50/80 => Train Loss: 0.7414, Train Accuracy: 0.7520 | Test Loss: 1.0316, Test Accuracy: 0.6301\n",
      "Epoch 60/80 => Train Loss: 0.6424, Train Accuracy: 0.7886 | Test Loss: 0.9523, Test Accuracy: 0.6745\n",
      "Epoch 70/80 => Train Loss: 0.5782, Train Accuracy: 0.8135 | Test Loss: 0.9057, Test Accuracy: 0.6993\n",
      "Epoch 80/80 => Train Loss: 0.5487, Train Accuracy: 0.8239 | Test Loss: 0.8791, Test Accuracy: 0.7098\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [128, 32, 8, 32]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.0005\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 4941.7084, Test Accuracy: 0.1242\n",
      "Epoch 10/100 => Train Loss: 4.0159, Train Accuracy: 0.1376 | Test Loss: 3.9624, Test Accuracy: 0.0810\n",
      "Epoch 20/100 => Train Loss: 4.1843, Train Accuracy: 0.1351 | Test Loss: 4.7170, Test Accuracy: 0.1111\n",
      "Epoch 30/100 => Train Loss: 4.3039, Train Accuracy: 0.1420 | Test Loss: 3.9966, Test Accuracy: 0.1242\n",
      "Epoch 40/100 => Train Loss: 4.7839, Train Accuracy: 0.1281 | Test Loss: 3.2612, Test Accuracy: 0.1242\n",
      "Epoch 50/100 => Train Loss: 4.3458, Train Accuracy: 0.1464 | Test Loss: 3.7602, Test Accuracy: 0.1242\n",
      "Epoch 60/100 => Train Loss: 4.1925, Train Accuracy: 0.1322 | Test Loss: 3.7678, Test Accuracy: 0.1020\n",
      "Epoch 70/100 => Train Loss: 4.3412, Train Accuracy: 0.1527 | Test Loss: 4.5581, Test Accuracy: 0.1020\n",
      "Epoch 80/100 => Train Loss: 4.7115, Train Accuracy: 0.1360 | Test Loss: 4.5047, Test Accuracy: 0.1007\n",
      "Epoch 90/100 => Train Loss: 3.9531, Train Accuracy: 0.1338 | Test Loss: 4.3914, Test Accuracy: 0.1020\n",
      "Epoch 100/100 => Train Loss: 4.0953, Train Accuracy: 0.1363 | Test Loss: 5.3771, Test Accuracy: 0.1111\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [4, 32, 0, 32]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 16\n",
      "Weight Decay: 1e-05\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 3221.3319, Test Accuracy: 0.1150\n",
      "Epoch 10/100 => Train Loss: 19.6515, Train Accuracy: 0.1631 | Test Loss: 7.9615, Test Accuracy: 0.1608\n",
      "Epoch 20/100 => Train Loss: 4.2346, Train Accuracy: 0.1821 | Test Loss: 5.3819, Test Accuracy: 0.1229\n",
      "Epoch 30/100 => Train Loss: 3.7159, Train Accuracy: 0.2581 | Test Loss: 5.3887, Test Accuracy: 0.2209\n",
      "Epoch 40/100 => Train Loss: 3.9856, Train Accuracy: 0.2673 | Test Loss: 3.2458, Test Accuracy: 0.1386\n",
      "Epoch 50/100 => Train Loss: 3.6182, Train Accuracy: 0.2600 | Test Loss: 2.8341, Test Accuracy: 0.1895\n",
      "Epoch 60/100 => Train Loss: 4.2723, Train Accuracy: 0.1426 | Test Loss: 4.5468, Test Accuracy: 0.1242\n",
      "Epoch 70/100 => Train Loss: 3.6243, Train Accuracy: 0.2338 | Test Loss: 3.6060, Test Accuracy: 0.1634\n",
      "Epoch 80/100 => Train Loss: 5.0964, Train Accuracy: 0.1259 | Test Loss: 9.2335, Test Accuracy: 0.1020\n",
      "Epoch 90/100 => Train Loss: 4.3647, Train Accuracy: 0.1262 | Test Loss: 7.1413, Test Accuracy: 0.1020\n",
      "Epoch 100/100 => Train Loss: 4.6147, Train Accuracy: 0.1297 | Test Loss: 3.1024, Test Accuracy: 0.1242\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [4, 16, 0, 16]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epochs: 90\n",
      "Epoch 0/90 => Test Loss: 9.5311, Test Accuracy: 0.0993\n",
      "Epoch 10/90 => Train Loss: 1.5833, Train Accuracy: 0.4894 | Test Loss: 1.9314, Test Accuracy: 0.3150\n",
      "Epoch 20/90 => Train Loss: 1.3934, Train Accuracy: 0.5607 | Test Loss: 1.7715, Test Accuracy: 0.4222\n",
      "Epoch 30/90 => Train Loss: 6.5526, Train Accuracy: 0.3102 | Test Loss: 6.5639, Test Accuracy: 0.2601\n",
      "Epoch 40/90 => Train Loss: 1.7256, Train Accuracy: 0.5222 | Test Loss: 3.0228, Test Accuracy: 0.4013\n",
      "Epoch 50/90 => Train Loss: 1.7569, Train Accuracy: 0.5046 | Test Loss: 2.6561, Test Accuracy: 0.3935\n",
      "Epoch 60/90 => Train Loss: 1.6523, Train Accuracy: 0.5188 | Test Loss: 2.1303, Test Accuracy: 0.3569\n",
      "Epoch 70/90 => Train Loss: 3.0257, Train Accuracy: 0.3976 | Test Loss: 2.8429, Test Accuracy: 0.2810\n",
      "Epoch 80/90 => Train Loss: 7.9887, Train Accuracy: 0.3443 | Test Loss: 11.1450, Test Accuracy: 0.1895\n",
      "Epoch 90/90 => Train Loss: 2.0151, Train Accuracy: 0.4203 | Test Loss: 2.0827, Test Accuracy: 0.2614\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [128, 8, 8, 4]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 16\n",
      "Weight Decay: 1e-05\n",
      "Epochs: 20\n",
      "Epoch 0/20 => Test Loss: 3.7927, Test Accuracy: 0.1150\n",
      "Epoch 10/20 => Train Loss: 2.1760, Train Accuracy: 0.2023 | Test Loss: 2.3949, Test Accuracy: 0.0941\n",
      "Epoch 20/20 => Train Loss: 2.1731, Train Accuracy: 0.1934 | Test Loss: 2.3848, Test Accuracy: 0.1020\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 8, 0, 4]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.0005\n",
      "Epochs: 20\n",
      "Epoch 0/20 => Test Loss: 2.3387, Test Accuracy: 0.0850\n",
      "Epoch 10/20 => Train Loss: 1.1496, Train Accuracy: 0.6213 | Test Loss: 1.3743, Test Accuracy: 0.4915\n",
      "Epoch 20/20 => Train Loss: 0.9731, Train Accuracy: 0.6800 | Test Loss: 1.1266, Test Accuracy: 0.6222\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [4, 16, 0, 8]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 4\n",
      "Weight Decay: 1e-05\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 10092.9960, Test Accuracy: 0.0562\n",
      "Epoch 10/100 => Train Loss: 7.8134, Train Accuracy: 0.1423 | Test Loss: 3.7798, Test Accuracy: 0.1033\n",
      "Epoch 20/100 => Train Loss: 5.4760, Train Accuracy: 0.1300 | Test Loss: 9.2647, Test Accuracy: 0.0941\n",
      "Epoch 30/100 => Train Loss: 6.3490, Train Accuracy: 0.1401 | Test Loss: 10.8954, Test Accuracy: 0.1020\n",
      "Epoch 40/100 => Train Loss: 6.8607, Train Accuracy: 0.1398 | Test Loss: 8.2308, Test Accuracy: 0.1203\n",
      "Epoch 50/100 => Train Loss: 6.6765, Train Accuracy: 0.1379 | Test Loss: 9.5990, Test Accuracy: 0.0549\n",
      "Epoch 60/100 => Train Loss: 5.4711, Train Accuracy: 0.1382 | Test Loss: 10.4450, Test Accuracy: 0.1020\n",
      "Epoch 70/100 => Train Loss: 6.3773, Train Accuracy: 0.1284 | Test Loss: 9.3420, Test Accuracy: 0.0810\n",
      "Epoch 80/100 => Train Loss: 6.5949, Train Accuracy: 0.1291 | Test Loss: 3.5032, Test Accuracy: 0.1111\n",
      "Epoch 90/100 => Train Loss: 7.1369, Train Accuracy: 0.1243 | Test Loss: 3.3556, Test Accuracy: 0.1007\n",
      "Epoch 100/100 => Train Loss: 6.2431, Train Accuracy: 0.1183 | Test Loss: 8.5776, Test Accuracy: 0.1111\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [64, 0, 64, 8]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.001\n",
      "Epochs: 40\n",
      "Epoch 0/40 => Test Loss: 2.7685, Test Accuracy: 0.0575\n",
      "Epoch 10/40 => Train Loss: 1.2075, Train Accuracy: 0.6346 | Test Loss: 1.4214, Test Accuracy: 0.5359\n",
      "Epoch 20/40 => Train Loss: 0.9955, Train Accuracy: 0.6920 | Test Loss: 1.1903, Test Accuracy: 0.5974\n",
      "Epoch 30/40 => Train Loss: 0.8912, Train Accuracy: 0.7248 | Test Loss: 1.0770, Test Accuracy: 0.6471\n",
      "Epoch 40/40 => Train Loss: 0.8273, Train Accuracy: 0.7476 | Test Loss: 0.9952, Test Accuracy: 0.6758\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [128, 32, 8, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 128\n",
      "Weight Decay: 0.001\n",
      "Epochs: 40\n",
      "Epoch 0/40 => Test Loss: 1000.7589, Test Accuracy: 0.0850\n",
      "Epoch 10/40 => Train Loss: 5.1353, Train Accuracy: 0.1306 | Test Loss: 9.0697, Test Accuracy: 0.1020\n",
      "Epoch 20/40 => Train Loss: 5.3391, Train Accuracy: 0.1338 | Test Loss: 9.0401, Test Accuracy: 0.1111\n",
      "Epoch 30/40 => Train Loss: 8.4843, Train Accuracy: 0.1360 | Test Loss: 11.0426, Test Accuracy: 0.1203\n",
      "Epoch 40/40 => Train Loss: 5.4982, Train Accuracy: 0.1338 | Test Loss: 6.3363, Test Accuracy: 0.1007\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 16, 0, 8]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 4\n",
      "Weight Decay: 1e-05\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 4764.1806, Test Accuracy: 0.0758\n",
      "Epoch 10/100 => Train Loss: 6.0346, Train Accuracy: 0.1855 | Test Loss: 3.9782, Test Accuracy: 0.2431\n",
      "Epoch 20/100 => Train Loss: 6.5223, Train Accuracy: 0.2322 | Test Loss: 3.5482, Test Accuracy: 0.2314\n",
      "Epoch 30/100 => Train Loss: 7.1658, Train Accuracy: 0.2354 | Test Loss: 5.5220, Test Accuracy: 0.1843\n",
      "Epoch 40/100 => Train Loss: 5.8607, Train Accuracy: 0.2670 | Test Loss: 5.4176, Test Accuracy: 0.1882\n",
      "Epoch 50/100 => Train Loss: 5.8602, Train Accuracy: 0.2490 | Test Loss: 5.2278, Test Accuracy: 0.2157\n",
      "Epoch 60/100 => Train Loss: 5.3920, Train Accuracy: 0.2771 | Test Loss: 7.5844, Test Accuracy: 0.1948\n",
      "Epoch 70/100 => Train Loss: 5.8553, Train Accuracy: 0.2244 | Test Loss: 68.5911, Test Accuracy: 0.2314\n",
      "Epoch 80/100 => Train Loss: 5.7211, Train Accuracy: 0.2395 | Test Loss: 4.6088, Test Accuracy: 0.2144\n",
      "Epoch 90/100 => Train Loss: 5.7506, Train Accuracy: 0.2329 | Test Loss: 4.8221, Test Accuracy: 0.2052\n",
      "Epoch 100/100 => Train Loss: 7.1607, Train Accuracy: 0.2666 | Test Loss: 6.1321, Test Accuracy: 0.2118\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [128, 32, 4, 0]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Weight Decay: 0.0005\n",
      "Epochs: 40\n",
      "Epoch 0/40 => Test Loss: 67.4470, Test Accuracy: 0.0810\n",
      "Epoch 10/40 => Train Loss: 2.6240, Train Accuracy: 0.2158 | Test Loss: 3.0520, Test Accuracy: 0.1516\n",
      "Epoch 20/40 => Train Loss: 2.5537, Train Accuracy: 0.3856 | Test Loss: 2.5811, Test Accuracy: 0.3320\n",
      "Epoch 30/40 => Train Loss: 2.3299, Train Accuracy: 0.3894 | Test Loss: 3.1327, Test Accuracy: 0.3203\n",
      "Epoch 40/40 => Train Loss: 2.3898, Train Accuracy: 0.3929 | Test Loss: 4.0527, Test Accuracy: 0.1948\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [64, 32, 64, 32]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.001\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 216.5106, Test Accuracy: 0.0941\n",
      "Epoch 10/100 => Train Loss: 7.9753, Train Accuracy: 0.3468 | Test Loss: 9.4078, Test Accuracy: 0.2248\n",
      "Epoch 20/100 => Train Loss: 5.6872, Train Accuracy: 0.5087 | Test Loss: 6.2825, Test Accuracy: 0.4510\n",
      "Epoch 30/100 => Train Loss: 5.2340, Train Accuracy: 0.5431 | Test Loss: 19.6825, Test Accuracy: 0.2954\n",
      "Epoch 40/100 => Train Loss: 5.3876, Train Accuracy: 0.5749 | Test Loss: 9.4444, Test Accuracy: 0.4745\n",
      "Epoch 50/100 => Train Loss: 3.9510, Train Accuracy: 0.6160 | Test Loss: 5.6809, Test Accuracy: 0.5712\n",
      "Epoch 60/100 => Train Loss: 3.5774, Train Accuracy: 0.6068 | Test Loss: 4.8435, Test Accuracy: 0.5634\n",
      "Epoch 70/100 => Train Loss: 2.1812, Train Accuracy: 0.6747 | Test Loss: 5.5725, Test Accuracy: 0.5634\n",
      "Epoch 80/100 => Train Loss: 2.2601, Train Accuracy: 0.6986 | Test Loss: 3.3619, Test Accuracy: 0.6144\n",
      "Epoch 90/100 => Train Loss: 1.9246, Train Accuracy: 0.6731 | Test Loss: 5.8967, Test Accuracy: 0.6275\n",
      "Epoch 100/100 => Train Loss: 1.6955, Train Accuracy: 0.6791 | Test Loss: 3.8111, Test Accuracy: 0.5582\n",
      "Gen 1: \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 16, 0, 16]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 128\n",
      "Weight Decay: 0.0005\n",
      "Epochs: 80\n",
      "Epoch 0/80 => Test Loss: 2.4838, Test Accuracy: 0.0549\n",
      "Epoch 10/80 => Train Loss: 1.8004, Train Accuracy: 0.4733 | Test Loss: 2.0692, Test Accuracy: 0.2928\n",
      "Epoch 20/80 => Train Loss: 1.4015, Train Accuracy: 0.5342 | Test Loss: 1.6581, Test Accuracy: 0.3974\n",
      "Epoch 30/80 => Train Loss: 1.1931, Train Accuracy: 0.5973 | Test Loss: 1.4002, Test Accuracy: 0.4902\n",
      "Epoch 40/80 => Train Loss: 1.0822, Train Accuracy: 0.6321 | Test Loss: 1.3017, Test Accuracy: 0.5320\n",
      "Epoch 50/80 => Train Loss: 1.0197, Train Accuracy: 0.6630 | Test Loss: 1.2089, Test Accuracy: 0.5817\n",
      "Epoch 60/80 => Train Loss: 0.9647, Train Accuracy: 0.6825 | Test Loss: 1.1433, Test Accuracy: 0.5987\n",
      "Epoch 70/80 => Train Loss: 0.9424, Train Accuracy: 0.6885 | Test Loss: 1.1593, Test Accuracy: 0.5882\n",
      "Epoch 80/80 => Train Loss: 0.9135, Train Accuracy: 0.7018 | Test Loss: 1.1174, Test Accuracy: 0.6092\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [128, 16, 4, 8]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 4\n",
      "Weight Decay: 0.001\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 96.4606, Test Accuracy: 0.0536\n",
      "Epoch 10/100 => Train Loss: 6.7855, Train Accuracy: 0.2187 | Test Loss: 6.9008, Test Accuracy: 0.1791\n",
      "Epoch 20/100 => Train Loss: 5.0379, Train Accuracy: 0.4355 | Test Loss: 4.3463, Test Accuracy: 0.3333\n",
      "Epoch 30/100 => Train Loss: 4.1587, Train Accuracy: 0.4585 | Test Loss: 5.7492, Test Accuracy: 0.3072\n",
      "Epoch 40/100 => Train Loss: 4.6405, Train Accuracy: 0.5096 | Test Loss: 7.4705, Test Accuracy: 0.4183\n",
      "Epoch 50/100 => Train Loss: 4.2849, Train Accuracy: 0.5194 | Test Loss: 12.9511, Test Accuracy: 0.3778\n",
      "Epoch 60/100 => Train Loss: 5.2465, Train Accuracy: 0.5260 | Test Loss: 6.7004, Test Accuracy: 0.5176\n",
      "Epoch 70/100 => Train Loss: 4.6782, Train Accuracy: 0.5333 | Test Loss: 6.2145, Test Accuracy: 0.4784\n",
      "Epoch 80/100 => Train Loss: 4.7357, Train Accuracy: 0.5440 | Test Loss: 7.0791, Test Accuracy: 0.3059\n",
      "Epoch 90/100 => Train Loss: 3.6528, Train Accuracy: 0.5551 | Test Loss: 4.8936, Test Accuracy: 0.4758\n",
      "Epoch 100/100 => Train Loss: 4.3280, Train Accuracy: 0.5554 | Test Loss: 7.7954, Test Accuracy: 0.4837\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 0, 0, 8]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.0005\n",
      "Epochs: 40\n",
      "Epoch 0/40 => Test Loss: 2.2515, Test Accuracy: 0.2000\n",
      "Epoch 10/40 => Train Loss: 1.1679, Train Accuracy: 0.6317 | Test Loss: 1.3847, Test Accuracy: 0.5163\n",
      "Epoch 20/40 => Train Loss: 1.0326, Train Accuracy: 0.6715 | Test Loss: 1.2286, Test Accuracy: 0.5673\n",
      "Epoch 30/40 => Train Loss: 0.9844, Train Accuracy: 0.6854 | Test Loss: 1.1741, Test Accuracy: 0.6092\n",
      "Epoch 40/40 => Train Loss: 0.9524, Train Accuracy: 0.7024 | Test Loss: 1.1351, Test Accuracy: 0.6248\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [64, 16, 64, 8]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 4\n",
      "Weight Decay: 0.001\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 124.6134, Test Accuracy: 0.1098\n",
      "Epoch 10/100 => Train Loss: 10.3834, Train Accuracy: 0.3935 | Test Loss: 26.6616, Test Accuracy: 0.1137\n",
      "Epoch 20/100 => Train Loss: 9.0651, Train Accuracy: 0.5409 | Test Loss: 9.3080, Test Accuracy: 0.4209\n",
      "Epoch 30/100 => Train Loss: 4.1752, Train Accuracy: 0.5756 | Test Loss: 5.7142, Test Accuracy: 0.4784\n",
      "Epoch 40/100 => Train Loss: 2.6004, Train Accuracy: 0.6103 | Test Loss: 3.1015, Test Accuracy: 0.5752\n",
      "Epoch 50/100 => Train Loss: 2.0704, Train Accuracy: 0.6415 | Test Loss: 4.0409, Test Accuracy: 0.3791\n",
      "Epoch 60/100 => Train Loss: 1.5013, Train Accuracy: 0.6819 | Test Loss: 2.4165, Test Accuracy: 0.5451\n",
      "Epoch 70/100 => Train Loss: 1.4695, Train Accuracy: 0.6870 | Test Loss: 2.0586, Test Accuracy: 0.6235\n",
      "Epoch 80/100 => Train Loss: 1.2701, Train Accuracy: 0.7154 | Test Loss: 2.2032, Test Accuracy: 0.6026\n",
      "Epoch 90/100 => Train Loss: 1.0559, Train Accuracy: 0.7425 | Test Loss: 1.7492, Test Accuracy: 0.6575\n",
      "Epoch 100/100 => Train Loss: 1.0115, Train Accuracy: 0.7504 | Test Loss: 1.5943, Test Accuracy: 0.7072\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 32, 0, 32]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.0005\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 161.1160, Test Accuracy: 0.0549\n",
      "Epoch 10/100 => Train Loss: 11.8826, Train Accuracy: 0.3957 | Test Loss: 11.3297, Test Accuracy: 0.2562\n",
      "Epoch 20/100 => Train Loss: 5.3535, Train Accuracy: 0.4531 | Test Loss: 5.2574, Test Accuracy: 0.2928\n",
      "Epoch 30/100 => Train Loss: 3.0738, Train Accuracy: 0.5279 | Test Loss: 3.3916, Test Accuracy: 0.4065\n",
      "Epoch 40/100 => Train Loss: 2.8470, Train Accuracy: 0.5314 | Test Loss: 7.1893, Test Accuracy: 0.3804\n",
      "Epoch 50/100 => Train Loss: 2.6139, Train Accuracy: 0.5475 | Test Loss: 3.8705, Test Accuracy: 0.4588\n",
      "Epoch 60/100 => Train Loss: 2.6036, Train Accuracy: 0.5563 | Test Loss: 3.4080, Test Accuracy: 0.4261\n",
      "Epoch 70/100 => Train Loss: 2.1574, Train Accuracy: 0.5831 | Test Loss: 3.6248, Test Accuracy: 0.4523\n",
      "Epoch 80/100 => Train Loss: 2.0120, Train Accuracy: 0.5813 | Test Loss: 4.3876, Test Accuracy: 0.4562\n",
      "Epoch 90/100 => Train Loss: 1.9161, Train Accuracy: 0.5989 | Test Loss: 4.0087, Test Accuracy: 0.4379\n",
      "Epoch 100/100 => Train Loss: 1.8170, Train Accuracy: 0.6235 | Test Loss: 3.6765, Test Accuracy: 0.4458\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [64, 16, 64, 16]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 128\n",
      "Weight Decay: 0.001\n",
      "Epochs: 80\n",
      "Epoch 0/80 => Test Loss: 2.4075, Test Accuracy: 0.1085\n",
      "Epoch 10/80 => Train Loss: 1.9188, Train Accuracy: 0.4323 | Test Loss: 2.1787, Test Accuracy: 0.2667\n",
      "Epoch 20/80 => Train Loss: 1.6013, Train Accuracy: 0.5074 | Test Loss: 1.8875, Test Accuracy: 0.3778\n",
      "Epoch 30/80 => Train Loss: 1.3834, Train Accuracy: 0.5661 | Test Loss: 1.6796, Test Accuracy: 0.4183\n",
      "Epoch 40/80 => Train Loss: 1.1829, Train Accuracy: 0.6115 | Test Loss: 1.4576, Test Accuracy: 0.4549\n",
      "Epoch 50/80 => Train Loss: 0.9701, Train Accuracy: 0.6898 | Test Loss: 1.2160, Test Accuracy: 0.5739\n",
      "Epoch 60/80 => Train Loss: 0.8470, Train Accuracy: 0.7233 | Test Loss: 1.0805, Test Accuracy: 0.6458\n",
      "Epoch 70/80 => Train Loss: 0.7840, Train Accuracy: 0.7321 | Test Loss: 1.0236, Test Accuracy: 0.6431\n",
      "Epoch 80/80 => Train Loss: 0.7395, Train Accuracy: 0.7472 | Test Loss: 0.9972, Test Accuracy: 0.6484\n",
      "Gen 2: \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [64, 8, 64, 4]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.001\n",
      "Epochs: 20\n",
      "Epoch 0/20 => Test Loss: 2.5112, Test Accuracy: 0.1111\n",
      "Epoch 10/20 => Train Loss: 0.8747, Train Accuracy: 0.7027 | Test Loss: 0.9636, Test Accuracy: 0.6654\n",
      "Epoch 20/20 => Train Loss: 0.7225, Train Accuracy: 0.7611 | Test Loss: 0.8665, Test Accuracy: 0.7294\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [128, 0, 4, 8]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.001\n",
      "Epochs: 40\n",
      "Epoch 0/40 => Test Loss: 2.5011, Test Accuracy: 0.0837\n",
      "Epoch 10/40 => Train Loss: 0.6604, Train Accuracy: 0.7829 | Test Loss: 0.7788, Test Accuracy: 0.7425\n",
      "Epoch 20/40 => Train Loss: 0.5701, Train Accuracy: 0.8075 | Test Loss: 0.7373, Test Accuracy: 0.7373\n",
      "Epoch 30/40 => Train Loss: 0.4804, Train Accuracy: 0.8416 | Test Loss: 0.6331, Test Accuracy: 0.7935\n",
      "Epoch 40/40 => Train Loss: 0.4505, Train Accuracy: 0.8511 | Test Loss: 0.6657, Test Accuracy: 0.7778\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 8, 4, 8]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 4\n",
      "Weight Decay: 0.0005\n",
      "Epochs: 100\n",
      "Epoch 0/100 => Test Loss: 74.0159, Test Accuracy: 0.1007\n",
      "Epoch 10/100 => Train Loss: 3.5701, Train Accuracy: 0.3364 | Test Loss: 3.4634, Test Accuracy: 0.2471\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenetic_algorithm_n_gens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitness_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfitness_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_gens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 37\u001b[0m, in \u001b[0;36mgenetic_algorithm_n_gens\u001b[1;34m(population, fitness_function, parent_selection_function, survival_function, crossover_function, mutation_function, mutation_rate, allow_parents, n_gens, plot, display_last_gen)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m new_population \u001b[38;5;241m=\u001b[39m parent_selection_function(new_population, fitness_function, crossover_function, mutation_function, mutation_rate, allow_parents)\n\u001b[1;32m---> 37\u001b[0m new_population \u001b[38;5;241m=\u001b[39m \u001b[43msurvival_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_population\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitness_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m fitness_scores \u001b[38;5;241m=\u001b[39m [fitness_function(individual) \u001b[38;5;28;01mfor\u001b[39;00m individual \u001b[38;5;129;01min\u001b[39;00m new_population]\n\u001b[0;32m     39\u001b[0m best_scores \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msorted\u001b[39m(fitness_scores)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m, in \u001b[0;36mtruncation\u001b[1;34m(population, fitness_function, npop)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtruncation\u001b[39m(population,fitness_function, npop):\n\u001b[1;32m----> 5\u001b[0m     fitness_values \u001b[38;5;241m=\u001b[39m [\u001b[43mfitness_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindividual\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m individual \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[0;32m      6\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m argsort(fitness_values)[:npop]\n\u001b[0;32m      7\u001b[0m     selected_population \u001b[38;5;241m=\u001b[39m [population[index] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m indexes]\n",
      "Cell \u001b[1;32mIn[42], line 265\u001b[0m, in \u001b[0;36mfitness_function\u001b[1;34m(person, epochs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# Train the model and capture results\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 265\u001b[0m     train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m     test_acc, test_loss \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[0;32m    268\u001b[0m     train_accuracies\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "Cell \u001b[1;32mIn[42], line 165\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m    163\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[0;32m    164\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 165\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, data\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m    167\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[42], line 101\u001b[0m, in \u001b[0;36mGNNModelEA3.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     98\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_func(x)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Apply the second graph convolutional layer followed by ReLU activation\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_func(x)\n\u001b[0;32m    104\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden2(x, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:280\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatic graphs not supported in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGATConv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 280\u001b[0m     x_src \u001b[38;5;241m=\u001b[39m x_dst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H, C)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# If the module is initialized as bipartite, transform source\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# and destination node features separately:\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_src \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_dst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "genetic_algorithm_n_gens(persons, fitness_function=fitness_function, n_gens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_memo(Memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 0: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 8, 0, 4]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 128\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 108.9927, Test Accuracy: 0.1085\n",
      "Epoch 10/20 => Train Loss: 4.0764, Train Accuracy: 0.2831 | Test Loss: 4.8315, Test Accuracy: 0.2536\n",
      "Epoch 20/20 => Train Loss: 2.6375, Train Accuracy: 0.4339 | Test Loss: 3.4582, Test Accuracy: 0.2771\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [4, 4, 4, 32]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 16\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 85.4041, Test Accuracy: 0.1020\n",
      "Epoch 10/20 => Train Loss: 6.1450, Train Accuracy: 0.2073 | Test Loss: 5.8854, Test Accuracy: 0.1935\n",
      "Epoch 20/20 => Train Loss: 3.7793, Train Accuracy: 0.2837 | Test Loss: 5.4817, Test Accuracy: 0.2484\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 8, 4, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 7.8701, Test Accuracy: 0.0784\n",
      "Epoch 10/20 => Train Loss: 1.9376, Train Accuracy: 0.3733 | Test Loss: 2.2053, Test Accuracy: 0.2275\n",
      "Epoch 20/20 => Train Loss: 1.8594, Train Accuracy: 0.3960 | Test Loss: 1.9120, Test Accuracy: 0.2954\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 64, 8, 32]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 4789.2298, Test Accuracy: 0.0366\n",
      "Epoch 10/20 => Train Loss: 744.2899, Train Accuracy: 0.1316 | Test Loss: 485.5338, Test Accuracy: 0.1216\n",
      "Epoch 20/20 => Train Loss: 253.1437, Train Accuracy: 0.2367 | Test Loss: 395.1843, Test Accuracy: 0.2405\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 128, 0, 64]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 4\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 41.8809, Test Accuracy: 0.1373\n",
      "Epoch 10/20 => Train Loss: 1404.4898, Train Accuracy: 0.4364 | Test Loss: 2290.1102, Test Accuracy: 0.4052\n",
      "Epoch 20/20 => Train Loss: 1452.9635, Train Accuracy: 0.4553 | Test Loss: 4248.6206, Test Accuracy: 0.2889\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 32, 128, 4]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 5699.8131, Test Accuracy: 0.1098\n",
      "Epoch 10/20 => Train Loss: 5.7372, Train Accuracy: 0.1344 | Test Loss: 10.0092, Test Accuracy: 0.0810\n",
      "Epoch 20/20 => Train Loss: 6.0313, Train Accuracy: 0.1332 | Test Loss: 5.3660, Test Accuracy: 0.1111\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [0, 16, 8, 32]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.4099, Test Accuracy: 0.0614\n",
      "Epoch 10/20 => Train Loss: 1.7573, Train Accuracy: 0.5317 | Test Loss: 1.8825, Test Accuracy: 0.4222\n",
      "Epoch 20/20 => Train Loss: 1.6229, Train Accuracy: 0.6232 | Test Loss: 1.7721, Test Accuracy: 0.5072\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 16, 0, 4]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 128\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 129.9731, Test Accuracy: 0.0810\n",
      "Epoch 10/20 => Train Loss: 4.9404, Train Accuracy: 0.2253 | Test Loss: 9.0708, Test Accuracy: 0.1150\n",
      "Epoch 20/20 => Train Loss: 4.8766, Train Accuracy: 0.2758 | Test Loss: 4.8006, Test Accuracy: 0.1961\n",
      "Gen 1: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 16, 128, 64]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 4.2644, Test Accuracy: 0.0928\n",
      "Epoch 10/20 => Train Loss: 1.3839, Train Accuracy: 0.5409 | Test Loss: 1.6183, Test Accuracy: 0.4222\n",
      "Epoch 20/20 => Train Loss: 1.9388, Train Accuracy: 0.3414 | Test Loss: 2.1300, Test Accuracy: 0.2379\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 0, 8]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3531, Test Accuracy: 0.1333\n",
      "Epoch 10/20 => Train Loss: 1.2605, Train Accuracy: 0.5790 | Test Loss: 1.6126, Test Accuracy: 0.4693\n",
      "Epoch 20/20 => Train Loss: 1.1596, Train Accuracy: 0.6242 | Test Loss: 1.3460, Test Accuracy: 0.5386\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 128, 0, 128]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 4\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2594, Test Accuracy: 0.1778\n",
      "Epoch 10/20 => Train Loss: 7.2932, Train Accuracy: 0.4512 | Test Loss: 6.2279, Test Accuracy: 0.3895\n",
      "Epoch 20/20 => Train Loss: 6.7010, Train Accuracy: 0.4929 | Test Loss: 8.2413, Test Accuracy: 0.4209\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 8, 128, 128]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 3.6477, Test Accuracy: 0.1098\n",
      "Epoch 10/20 => Train Loss: 2.1768, Train Accuracy: 0.1988 | Test Loss: 2.3794, Test Accuracy: 0.0941\n",
      "Epoch 20/20 => Train Loss: 2.1732, Train Accuracy: 0.2023 | Test Loss: 2.4191, Test Accuracy: 0.0941\n",
      "Gen 2: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 4, 8, 8]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.4025, Test Accuracy: 0.1098\n",
      "Epoch 10/20 => Train Loss: 1.7444, Train Accuracy: 0.5541 | Test Loss: 1.8897, Test Accuracy: 0.4536\n",
      "Epoch 20/20 => Train Loss: 1.7134, Train Accuracy: 0.5671 | Test Loss: 1.8622, Test Accuracy: 0.4575\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [16, 4, 0, 8]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3205, Test Accuracy: 0.1124\n",
      "Epoch 10/20 => Train Loss: 1.0841, Train Accuracy: 0.6324 | Test Loss: 1.3708, Test Accuracy: 0.5190\n",
      "Epoch 20/20 => Train Loss: 1.0218, Train Accuracy: 0.6620 | Test Loss: 1.1868, Test Accuracy: 0.5895\n",
      "Gen 3: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 4, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3195, Test Accuracy: 0.0980\n",
      "Epoch 10/20 => Train Loss: 0.9080, Train Accuracy: 0.6971 | Test Loss: 1.1341, Test Accuracy: 0.6222\n",
      "Epoch 20/20 => Train Loss: 0.9146, Train Accuracy: 0.7024 | Test Loss: 1.0823, Test Accuracy: 0.6431\n",
      "Gen 4: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 4, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3801, Test Accuracy: 0.0693\n",
      "Epoch 10/20 => Train Loss: 1.8360, Train Accuracy: 0.4266 | Test Loss: 2.0622, Test Accuracy: 0.2614\n",
      "Epoch 20/20 => Train Loss: 1.5397, Train Accuracy: 0.4639 | Test Loss: 1.8336, Test Accuracy: 0.2928\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [16, 4, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3664, Test Accuracy: 0.0876\n",
      "Epoch 10/20 => Train Loss: 1.2563, Train Accuracy: 0.5926 | Test Loss: 1.5110, Test Accuracy: 0.5098\n",
      "Epoch 20/20 => Train Loss: 1.1272, Train Accuracy: 0.6134 | Test Loss: 1.2935, Test Accuracy: 0.5229\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 128, 8]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.4138, Test Accuracy: 0.0693\n",
      "Epoch 10/20 => Train Loss: 0.8166, Train Accuracy: 0.7485 | Test Loss: 1.0837, Test Accuracy: 0.6353\n",
      "Epoch 20/20 => Train Loss: 0.7415, Train Accuracy: 0.7728 | Test Loss: 0.9295, Test Accuracy: 0.7190\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 32\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 2.2995, Test Accuracy: 0.1229\n",
      "Epoch 10/20 => Train Loss: 0.9844, Train Accuracy: 0.6750 | Test Loss: 1.2038, Test Accuracy: 0.5869\n",
      "Epoch 20/20 => Train Loss: 0.9139, Train Accuracy: 0.7024 | Test Loss: 1.0780, Test Accuracy: 0.6549\n",
      "Gen 5: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 0, 0]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2968, Test Accuracy: 0.1412\n",
      "Epoch 10/20 => Train Loss: 0.9310, Train Accuracy: 0.6936 | Test Loss: 1.1053, Test Accuracy: 0.6105\n",
      "Epoch 20/20 => Train Loss: 0.8813, Train Accuracy: 0.7154 | Test Loss: 1.0838, Test Accuracy: 0.6222\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 128, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2906, Test Accuracy: 0.1268\n",
      "Epoch 10/20 => Train Loss: 1.0795, Train Accuracy: 0.6541 | Test Loss: 1.5416, Test Accuracy: 0.5516\n",
      "Epoch 20/20 => Train Loss: 0.9206, Train Accuracy: 0.6964 | Test Loss: 1.2423, Test Accuracy: 0.5843\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 0, 8]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3047, Test Accuracy: 0.1111\n",
      "Epoch 10/20 => Train Loss: 0.7841, Train Accuracy: 0.7548 | Test Loss: 0.8991, Test Accuracy: 0.7190\n",
      "Epoch 20/20 => Train Loss: 0.7475, Train Accuracy: 0.7583 | Test Loss: 0.9213, Test Accuracy: 0.6850\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 128, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3095, Test Accuracy: 0.0614\n",
      "Epoch 10/20 => Train Loss: 0.8527, Train Accuracy: 0.7176 | Test Loss: 1.0834, Test Accuracy: 0.6248\n",
      "Epoch 20/20 => Train Loss: 0.7930, Train Accuracy: 0.7400 | Test Loss: 0.9738, Test Accuracy: 0.6797\n",
      "Gen 6: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 0, 0]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3057, Test Accuracy: 0.1085\n",
      "Epoch 10/20 => Train Loss: 0.8596, Train Accuracy: 0.7135 | Test Loss: 1.0362, Test Accuracy: 0.6431\n",
      "Epoch 20/20 => Train Loss: 0.8258, Train Accuracy: 0.7277 | Test Loss: 0.9888, Test Accuracy: 0.6549\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 0, 4]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3997, Test Accuracy: 0.0549\n",
      "Epoch 10/20 => Train Loss: 0.9246, Train Accuracy: 0.6920 | Test Loss: 1.0997, Test Accuracy: 0.6353\n",
      "Epoch 20/20 => Train Loss: 0.8368, Train Accuracy: 0.7169 | Test Loss: 0.9760, Test Accuracy: 0.6876\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 4, 0, 0]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3377, Test Accuracy: 0.0980\n",
      "Epoch 10/20 => Train Loss: 0.9435, Train Accuracy: 0.6854 | Test Loss: 1.1544, Test Accuracy: 0.5961\n",
      "Epoch 20/20 => Train Loss: 0.9203, Train Accuracy: 0.6955 | Test Loss: 1.0367, Test Accuracy: 0.6471\n",
      "Gen 7: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 0, 8]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.4521, Test Accuracy: 0.0301\n",
      "Epoch 10/20 => Train Loss: 1.4943, Train Accuracy: 0.5377 | Test Loss: 1.7472, Test Accuracy: 0.3830\n",
      "Epoch 20/20 => Train Loss: 1.2240, Train Accuracy: 0.6283 | Test Loss: 1.4646, Test Accuracy: 0.5229\n",
      "Gen 8: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2790, Test Accuracy: 0.1242\n",
      "Epoch 10/20 => Train Loss: 0.7699, Train Accuracy: 0.7536 | Test Loss: 0.9369, Test Accuracy: 0.7176\n",
      "Epoch 20/20 => Train Loss: 0.6988, Train Accuracy: 0.7766 | Test Loss: 0.8585, Test Accuracy: 0.7281\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 4, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2982, Test Accuracy: 0.1268\n",
      "Epoch 10/20 => Train Loss: 0.9668, Train Accuracy: 0.6803 | Test Loss: 1.0856, Test Accuracy: 0.6105\n",
      "Epoch 20/20 => Train Loss: 0.9332, Train Accuracy: 0.6882 | Test Loss: 1.0872, Test Accuracy: 0.6222\n",
      "Gen 9: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 4, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2987, Test Accuracy: 0.1150\n",
      "Epoch 10/20 => Train Loss: 0.9636, Train Accuracy: 0.6769 | Test Loss: 1.1365, Test Accuracy: 0.6013\n",
      "Epoch 20/20 => Train Loss: 0.9213, Train Accuracy: 0.6911 | Test Loss: 1.0558, Test Accuracy: 0.6418\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 4, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 25.2365, Test Accuracy: 0.0915\n",
      "Epoch 10/20 => Train Loss: 23.8567, Train Accuracy: 0.2452 | Test Loss: 24.7263, Test Accuracy: 0.1621\n",
      "Epoch 20/20 => Train Loss: 22.1944, Train Accuracy: 0.2771 | Test Loss: 26.7133, Test Accuracy: 0.2405\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3230, Test Accuracy: 0.0850\n",
      "Epoch 10/20 => Train Loss: 0.7676, Train Accuracy: 0.7529 | Test Loss: 0.8738, Test Accuracy: 0.7203\n",
      "Epoch 20/20 => Train Loss: 0.6809, Train Accuracy: 0.7744 | Test Loss: 0.8622, Test Accuracy: 0.7085\n",
      "Gen 10: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3808, Test Accuracy: 0.0627\n",
      "Epoch 10/20 => Train Loss: 0.8312, Train Accuracy: 0.7327 | Test Loss: 0.9525, Test Accuracy: 0.6980\n",
      "Epoch 20/20 => Train Loss: 0.7725, Train Accuracy: 0.7447 | Test Loss: 0.9564, Test Accuracy: 0.6732\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 0, 4]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.4810, Test Accuracy: 0.0967\n",
      "Epoch 10/20 => Train Loss: 0.8390, Train Accuracy: 0.7264 | Test Loss: 1.0604, Test Accuracy: 0.6327\n",
      "Epoch 20/20 => Train Loss: 0.7380, Train Accuracy: 0.7611 | Test Loss: 0.9309, Test Accuracy: 0.7111\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.0005\n",
      "Epoch 0/20 => Test Loss: 2.3099, Test Accuracy: 0.0575\n",
      "Epoch 10/20 => Train Loss: 0.8883, Train Accuracy: 0.6990 | Test Loss: 1.0951, Test Accuracy: 0.6105\n",
      "Epoch 20/20 => Train Loss: 0.8855, Train Accuracy: 0.7053 | Test Loss: 1.1059, Test Accuracy: 0.6366\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [16, 4, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3299, Test Accuracy: 0.0797\n",
      "Epoch 10/20 => Train Loss: 0.8742, Train Accuracy: 0.7078 | Test Loss: 1.0107, Test Accuracy: 0.6523\n",
      "Epoch 20/20 => Train Loss: 0.8473, Train Accuracy: 0.7087 | Test Loss: 1.0017, Test Accuracy: 0.6588\n",
      "Gen 11: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 64, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.4172, Test Accuracy: 0.0484\n",
      "Epoch 10/20 => Train Loss: 0.8281, Train Accuracy: 0.7315 | Test Loss: 0.9906, Test Accuracy: 0.6471\n",
      "Epoch 20/20 => Train Loss: 0.7919, Train Accuracy: 0.7460 | Test Loss: 0.9520, Test Accuracy: 0.6758\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3528, Test Accuracy: 0.0680\n",
      "Epoch 10/20 => Train Loss: 0.9077, Train Accuracy: 0.7078 | Test Loss: 1.1035, Test Accuracy: 0.6144\n",
      "Epoch 20/20 => Train Loss: 0.8586, Train Accuracy: 0.7214 | Test Loss: 1.0793, Test Accuracy: 0.6588\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3500, Test Accuracy: 0.1111\n",
      "Epoch 10/20 => Train Loss: 0.7944, Train Accuracy: 0.7472 | Test Loss: 0.9289, Test Accuracy: 0.6902\n",
      "Epoch 20/20 => Train Loss: 0.7127, Train Accuracy: 0.7687 | Test Loss: 0.9349, Test Accuracy: 0.6967\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 4, 4, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3526, Test Accuracy: 0.0641\n",
      "Epoch 10/20 => Train Loss: 1.0080, Train Accuracy: 0.6636 | Test Loss: 1.1155, Test Accuracy: 0.5660\n",
      "Epoch 20/20 => Train Loss: 0.9587, Train Accuracy: 0.6813 | Test Loss: 1.2107, Test Accuracy: 0.5621\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2274, Test Accuracy: 0.2575\n",
      "Epoch 10/20 => Train Loss: 0.7194, Train Accuracy: 0.7649 | Test Loss: 0.9230, Test Accuracy: 0.6941\n",
      "Epoch 20/20 => Train Loss: 0.6289, Train Accuracy: 0.7980 | Test Loss: 0.8063, Test Accuracy: 0.7503\n",
      "Gen 12: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 0, 0]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2363, Test Accuracy: 0.2431\n",
      "Epoch 10/20 => Train Loss: 0.7488, Train Accuracy: 0.7523 | Test Loss: 0.9282, Test Accuracy: 0.7098\n",
      "Epoch 20/20 => Train Loss: 0.7217, Train Accuracy: 0.7706 | Test Loss: 0.9352, Test Accuracy: 0.7163\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.0005\n",
      "Epoch 0/20 => Test Loss: 2.2599, Test Accuracy: 0.2418\n",
      "Epoch 10/20 => Train Loss: 0.8136, Train Accuracy: 0.7362 | Test Loss: 1.0486, Test Accuracy: 0.6458\n",
      "Epoch 20/20 => Train Loss: 0.7367, Train Accuracy: 0.7573 | Test Loss: 0.9527, Test Accuracy: 0.6967\n",
      "Gen 13: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [16, 0, 0, 8]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.4025, Test Accuracy: 0.1085\n",
      "Epoch 10/20 => Train Loss: 0.9808, Train Accuracy: 0.6791 | Test Loss: 1.1694, Test Accuracy: 0.5935\n",
      "Epoch 20/20 => Train Loss: 0.8848, Train Accuracy: 0.7034 | Test Loss: 1.4475, Test Accuracy: 0.4954\n",
      "Gen 14: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 4, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3744, Test Accuracy: 0.0627\n",
      "Epoch 10/20 => Train Loss: 0.9208, Train Accuracy: 0.6895 | Test Loss: 1.1640, Test Accuracy: 0.5882\n",
      "Epoch 20/20 => Train Loss: 0.8203, Train Accuracy: 0.7223 | Test Loss: 1.0520, Test Accuracy: 0.6235\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 3.0636, Test Accuracy: 0.1190\n",
      "Epoch 10/20 => Train Loss: 0.9959, Train Accuracy: 0.6844 | Test Loss: 1.2866, Test Accuracy: 0.6026\n",
      "Epoch 20/20 => Train Loss: 0.9409, Train Accuracy: 0.7021 | Test Loss: 1.1649, Test Accuracy: 0.6418\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 128, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3969, Test Accuracy: 0.1359\n",
      "Epoch 10/20 => Train Loss: 0.7595, Train Accuracy: 0.7580 | Test Loss: 0.9929, Test Accuracy: 0.6784\n",
      "Epoch 20/20 => Train Loss: 0.6654, Train Accuracy: 0.7861 | Test Loss: 0.9025, Test Accuracy: 0.7137\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [64, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 32\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2913, Test Accuracy: 0.1425\n",
      "Epoch 10/20 => Train Loss: 0.8255, Train Accuracy: 0.7523 | Test Loss: 1.1276, Test Accuracy: 0.6889\n",
      "Epoch 20/20 => Train Loss: 0.8350, Train Accuracy: 0.7466 | Test Loss: 1.1078, Test Accuracy: 0.6549\n",
      "Gen 15: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.6802, Test Accuracy: 0.0562\n",
      "Epoch 10/20 => Train Loss: 1.1547, Train Accuracy: 0.6617 | Test Loss: 1.4969, Test Accuracy: 0.5529\n",
      "Epoch 20/20 => Train Loss: 1.3468, Train Accuracy: 0.6321 | Test Loss: 1.4920, Test Accuracy: 0.5346\n",
      "Gen 16: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 4, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.4123, Test Accuracy: 0.0745\n",
      "Epoch 10/20 => Train Loss: 0.7262, Train Accuracy: 0.7630 | Test Loss: 0.9153, Test Accuracy: 0.6980\n",
      "Epoch 20/20 => Train Loss: 0.6374, Train Accuracy: 0.7962 | Test Loss: 0.8776, Test Accuracy: 0.7255\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 2.4489, Test Accuracy: 0.0497\n",
      "Epoch 10/20 => Train Loss: 0.7218, Train Accuracy: 0.7725 | Test Loss: 0.9221, Test Accuracy: 0.6837\n",
      "Epoch 20/20 => Train Loss: 0.6276, Train Accuracy: 0.8034 | Test Loss: 0.8072, Test Accuracy: 0.7307\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3666, Test Accuracy: 0.1425\n",
      "Epoch 10/20 => Train Loss: 0.6314, Train Accuracy: 0.7908 | Test Loss: 0.8375, Test Accuracy: 0.7294\n",
      "Epoch 20/20 => Train Loss: 0.5632, Train Accuracy: 0.8072 | Test Loss: 0.7397, Test Accuracy: 0.7464\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 4, 128, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2825, Test Accuracy: 0.1137\n",
      "Epoch 10/20 => Train Loss: 0.9275, Train Accuracy: 0.6939 | Test Loss: 1.3958, Test Accuracy: 0.5817\n",
      "Epoch 20/20 => Train Loss: 1.0362, Train Accuracy: 0.6715 | Test Loss: 1.2827, Test Accuracy: 0.6078\n",
      "Gen 17: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [64, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.5570, Test Accuracy: 0.0549\n",
      "Epoch 10/20 => Train Loss: 0.7336, Train Accuracy: 0.7719 | Test Loss: 1.0464, Test Accuracy: 0.6784\n",
      "Epoch 20/20 => Train Loss: 0.6692, Train Accuracy: 0.7914 | Test Loss: 0.8362, Test Accuracy: 0.7320\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [32, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.6011, Test Accuracy: 0.0758\n",
      "Epoch 10/20 => Train Loss: 0.8153, Train Accuracy: 0.7311 | Test Loss: 1.0548, Test Accuracy: 0.6601\n",
      "Epoch 20/20 => Train Loss: 0.7524, Train Accuracy: 0.7463 | Test Loss: 0.9890, Test Accuracy: 0.6889\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 0, 4]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 10.1147, Test Accuracy: 0.0784\n",
      "Epoch 10/20 => Train Loss: 46.3268, Train Accuracy: 0.2644 | Test Loss: 21.1167, Test Accuracy: 0.3216\n",
      "Epoch 20/20 => Train Loss: 86.0509, Train Accuracy: 0.3137 | Test Loss: 49.4395, Test Accuracy: 0.2967\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 0, 0]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2459, Test Accuracy: 0.1503\n",
      "Epoch 10/20 => Train Loss: 0.7267, Train Accuracy: 0.7674 | Test Loss: 0.8397, Test Accuracy: 0.7294\n",
      "Epoch 20/20 => Train Loss: 0.6706, Train Accuracy: 0.7772 | Test Loss: 0.8763, Test Accuracy: 0.7294\n",
      "Gen 18: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.4381, Test Accuracy: 0.1111\n",
      "Epoch 10/20 => Train Loss: 0.6659, Train Accuracy: 0.7927 | Test Loss: 0.8614, Test Accuracy: 0.6954\n",
      "Epoch 20/20 => Train Loss: 0.6288, Train Accuracy: 0.7939 | Test Loss: 0.8124, Test Accuracy: 0.7412\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 0, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 102.3596, Test Accuracy: 0.0784\n",
      "Epoch 10/20 => Train Loss: 121.0567, Train Accuracy: 0.4468 | Test Loss: 147.4905, Test Accuracy: 0.4105\n",
      "Epoch 20/20 => Train Loss: 109.8546, Train Accuracy: 0.5248 | Test Loss: 183.0227, Test Accuracy: 0.5098\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [32, 128, 0, 4]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 34.8140, Test Accuracy: 0.0510\n",
      "Epoch 10/20 => Train Loss: 434.3716, Train Accuracy: 0.4206 | Test Loss: 509.0827, Test Accuracy: 0.4078\n",
      "Epoch 20/20 => Train Loss: 352.6548, Train Accuracy: 0.4790 | Test Loss: 519.5903, Test Accuracy: 0.4261\n",
      "Gen 19: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 20 with tournament_fitness_based_selection and truncation\n",
      "1. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n",
      "2. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n",
      "3. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n",
      "4. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n",
      "5. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n",
      "6. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n",
      "7. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n",
      "8. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n",
      "9. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n",
      "10. Path = [0, 4, 0, 0, 1, 1, 1, 4, 4, 0], Score = 0.7503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tournament_fitness_based_selection + truncation',\n",
       " [0.4444444444444444,\n",
       "  0.6666666666666666,\n",
       "  0.6666666666666666,\n",
       "  0.6941176470588235,\n",
       "  0.6941176470588235,\n",
       "  0.7189542483660131,\n",
       "  0.7189542483660131,\n",
       "  0.7189542483660131,\n",
       "  0.7189542483660131,\n",
       "  0.7281045751633987,\n",
       "  0.7281045751633987,\n",
       "  0.7281045751633987,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209],\n",
       " [0.28418300653594775,\n",
       "  0.4673202614379085,\n",
       "  0.6112418300653595,\n",
       "  0.6694117647058823,\n",
       "  0.6803921568627451,\n",
       "  0.6966013071895425,\n",
       "  0.6966013071895425,\n",
       "  0.6966013071895425,\n",
       "  0.6966013071895425,\n",
       "  0.7,\n",
       "  0.7082352941176471,\n",
       "  0.7281045751633987,\n",
       "  0.7303267973856209,\n",
       "  0.7347712418300654,\n",
       "  0.7481045751633987,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209,\n",
       "  0.7503267973856209])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_algorithm_n_gens(persons, fitness_function=fitness_function, n_gens=20, parent_selection_function=tournament_fitness_based_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [8, 16, 128, 32]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.05\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adeel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20 => Test Loss: 3.5890, Test Accuracy: 0.0863\n",
      "Epoch 10/20 => Train Loss: 1.6278, Train Accuracy: 0.4017 | Test Loss: 1.7600, Test Accuracy: 0.3529\n",
      "Epoch 20/20 => Train Loss: 1.5897, Train Accuracy: 0.4222 | Test Loss: 1.7588, Test Accuracy: 0.3438\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [32, 32, 4, 4]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 16\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 100.2208, Test Accuracy: 0.0549\n",
      "Epoch 10/20 => Train Loss: 27.4891, Train Accuracy: 0.1319 | Test Loss: 44.4711, Test Accuracy: 0.0941\n",
      "Epoch 20/20 => Train Loss: 24.4951, Train Accuracy: 0.1303 | Test Loss: 51.1555, Test Accuracy: 0.1020\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 64, 128]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 32\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 91.5610, Test Accuracy: 0.0706\n",
      "Epoch 10/20 => Train Loss: 46.6178, Train Accuracy: 0.2679 | Test Loss: 54.5953, Test Accuracy: 0.2000\n",
      "Epoch 20/20 => Train Loss: 35.4945, Train Accuracy: 0.2578 | Test Loss: 45.8648, Test Accuracy: 0.1974\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [4, 8, 4, 4]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 121.2384, Test Accuracy: 0.0810\n",
      "Epoch 10/20 => Train Loss: 3.0802, Train Accuracy: 0.2297 | Test Loss: 3.0506, Test Accuracy: 0.1412\n",
      "Epoch 20/20 => Train Loss: 3.1704, Train Accuracy: 0.3124 | Test Loss: 3.4568, Test Accuracy: 0.2510\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 64, 4, 32]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 9.2525, Test Accuracy: 0.0732\n",
      "Epoch 10/20 => Train Loss: 2.1657, Train Accuracy: 0.2023 | Test Loss: 2.3875, Test Accuracy: 0.0941\n",
      "Epoch 20/20 => Train Loss: 2.1655, Train Accuracy: 0.2023 | Test Loss: 2.3902, Test Accuracy: 0.0941\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 4, 16, 8]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 7.2215, Test Accuracy: 0.0837\n",
      "Epoch 10/20 => Train Loss: 2.1566, Train Accuracy: 0.4266 | Test Loss: 2.5282, Test Accuracy: 0.3425\n",
      "Epoch 20/20 => Train Loss: 1.9628, Train Accuracy: 0.4506 | Test Loss: 2.2147, Test Accuracy: 0.3621\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 4, 0, 32]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 73.9112, Test Accuracy: 0.1242\n",
      "Epoch 10/20 => Train Loss: 4.2500, Train Accuracy: 0.2979 | Test Loss: 5.4126, Test Accuracy: 0.2196\n",
      "Epoch 20/20 => Train Loss: 3.2513, Train Accuracy: 0.4181 | Test Loss: 3.2746, Test Accuracy: 0.3033\n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [0, 32, 8, 4]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 40.2813, Test Accuracy: 0.0706\n",
      "Epoch 10/20 => Train Loss: 20.0071, Train Accuracy: 0.2607 | Test Loss: 26.8045, Test Accuracy: 0.1621\n",
      "Epoch 20/20 => Train Loss: 16.8953, Train Accuracy: 0.3443 | Test Loss: 23.9633, Test Accuracy: 0.2288\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [16, 128, 0, 64]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 4\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3095, Test Accuracy: 0.1033\n",
      "Epoch 10/20 => Train Loss: 6.6957, Train Accuracy: 0.3957 | Test Loss: 7.0736, Test Accuracy: 0.3373\n",
      "Epoch 20/20 => Train Loss: 7.1911, Train Accuracy: 0.4437 | Test Loss: 8.8795, Test Accuracy: 0.3412\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 8, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 6.4096, Test Accuracy: 0.0837\n",
      "Epoch 10/20 => Train Loss: 1.8693, Train Accuracy: 0.4787 | Test Loss: 2.1263, Test Accuracy: 0.3725\n",
      "Epoch 20/20 => Train Loss: 2.2157, Train Accuracy: 0.5096 | Test Loss: 3.1531, Test Accuracy: 0.4471\n",
      "Gen 0: \n",
      "Gen 1: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 4, 0, 32]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 8\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 53.7346, Test Accuracy: 0.1242\n",
      "Epoch 10/20 => Train Loss: 3.9147, Train Accuracy: 0.3096 | Test Loss: 5.7424, Test Accuracy: 0.1856\n",
      "Epoch 20/20 => Train Loss: 3.6980, Train Accuracy: 0.4664 | Test Loss: 4.8310, Test Accuracy: 0.3673\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [8, 4, 128, 32]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 16\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 83.6389, Test Accuracy: 0.1007\n",
      "Epoch 10/20 => Train Loss: 14.6344, Train Accuracy: 0.1458 | Test Loss: 17.3703, Test Accuracy: 0.1007\n",
      "Epoch 20/20 => Train Loss: 7.0676, Train Accuracy: 0.1821 | Test Loss: 11.2604, Test Accuracy: 0.0549\n",
      "Gen 2: \n",
      "Gen 3: \n",
      "Gen 4: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 8, 0]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3592, Test Accuracy: 0.0366\n",
      "Epoch 10/20 => Train Loss: 1.9921, Train Accuracy: 0.5109 | Test Loss: 2.1065, Test Accuracy: 0.3582\n",
      "Epoch 20/20 => Train Loss: 1.9718, Train Accuracy: 0.5355 | Test Loss: 2.0746, Test Accuracy: 0.3882\n",
      "Gen 5: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 8, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.005\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 7.1216, Test Accuracy: 0.0954\n",
      "Epoch 10/20 => Train Loss: 2.8472, Train Accuracy: 0.2865 | Test Loss: 3.2251, Test Accuracy: 0.2131\n",
      "Epoch 20/20 => Train Loss: 2.3751, Train Accuracy: 0.4036 | Test Loss: 2.6960, Test Accuracy: 0.2928\n",
      "Gen 6: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 8, 128]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 5.3344, Test Accuracy: 0.1464\n",
      "Epoch 10/20 => Train Loss: 1.8111, Train Accuracy: 0.5062 | Test Loss: 1.9627, Test Accuracy: 0.3569\n",
      "Epoch 20/20 => Train Loss: 1.7750, Train Accuracy: 0.5257 | Test Loss: 1.8170, Test Accuracy: 0.4484\n",
      "Gen 7: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 8, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_max_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 18.2988, Test Accuracy: 0.1072\n",
      "Epoch 10/20 => Train Loss: 6.1210, Train Accuracy: 0.3720 | Test Loss: 5.6474, Test Accuracy: 0.3190\n",
      "Epoch 20/20 => Train Loss: 3.8521, Train Accuracy: 0.4916 | Test Loss: 3.9579, Test Accuracy: 0.4183\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 8, 0]\n",
      "Activation Function: tanh\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3618, Test Accuracy: 0.0614\n",
      "Epoch 10/20 => Train Loss: 1.7226, Train Accuracy: 0.5478 | Test Loss: 1.8672, Test Accuracy: 0.4248\n",
      "Epoch 20/20 => Train Loss: 1.7088, Train Accuracy: 0.5544 | Test Loss: 1.8514, Test Accuracy: 0.4261\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 4.9747, Test Accuracy: 0.0641\n",
      "Epoch 10/20 => Train Loss: 1.9442, Train Accuracy: 0.4938 | Test Loss: 1.9988, Test Accuracy: 0.4523\n",
      "Epoch 20/20 => Train Loss: 1.6218, Train Accuracy: 0.5522 | Test Loss: 1.8486, Test Accuracy: 0.4627\n",
      "Gen 8: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 16, 8, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 5.7210, Test Accuracy: 0.0863\n",
      "Epoch 10/20 => Train Loss: 2.2267, Train Accuracy: 0.3746 | Test Loss: 2.3101, Test Accuracy: 0.2915\n",
      "Epoch 20/20 => Train Loss: 1.8811, Train Accuracy: 0.4557 | Test Loss: 2.0877, Test Accuracy: 0.4261\n",
      "Gen 9: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [4, 8, 8, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 3.7181, Test Accuracy: 0.1281\n",
      "Epoch 10/20 => Train Loss: 1.3036, Train Accuracy: 0.5712 | Test Loss: 1.5694, Test Accuracy: 0.4275\n",
      "Epoch 20/20 => Train Loss: 1.4090, Train Accuracy: 0.6175 | Test Loss: 2.1328, Test Accuracy: 0.4510\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 4, 8, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 6.0230, Test Accuracy: 0.1856\n",
      "Epoch 10/20 => Train Loss: 1.7124, Train Accuracy: 0.4926 | Test Loss: 1.8476, Test Accuracy: 0.3922\n",
      "Epoch 20/20 => Train Loss: 1.6261, Train Accuracy: 0.5276 | Test Loss: 1.9884, Test Accuracy: 0.3935\n",
      "Gen 10: \n",
      "Layer Type: GATConv\n",
      "Hidden Dimensions: [0, 8, 8, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 9.5480, Test Accuracy: 0.0627\n",
      "Epoch 10/20 => Train Loss: 1.8207, Train Accuracy: 0.4506 | Test Loss: 2.0507, Test Accuracy: 0.3255\n",
      "Epoch 20/20 => Train Loss: 1.6179, Train Accuracy: 0.5563 | Test Loss: 2.1255, Test Accuracy: 0.4039\n",
      "Gen 11: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 4, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 6.0676, Test Accuracy: 0.0771\n",
      "Epoch 10/20 => Train Loss: 2.1900, Train Accuracy: 0.4547 | Test Loss: 2.3347, Test Accuracy: 0.3203\n",
      "Epoch 20/20 => Train Loss: 1.6543, Train Accuracy: 0.5639 | Test Loss: 1.9291, Test Accuracy: 0.4654\n",
      "Gen 12: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 4, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 6.4934, Test Accuracy: 0.1869\n",
      "Epoch 10/20 => Train Loss: 2.1508, Train Accuracy: 0.3395 | Test Loss: 2.2623, Test Accuracy: 0.3320\n",
      "Epoch 20/20 => Train Loss: 2.0892, Train Accuracy: 0.4251 | Test Loss: 2.6754, Test Accuracy: 0.3281\n",
      "Gen 13: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 16, 0]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.2779, Test Accuracy: 0.1098\n",
      "Epoch 10/20 => Train Loss: 1.9822, Train Accuracy: 0.5178 | Test Loss: 2.0817, Test Accuracy: 0.3817\n",
      "Epoch 20/20 => Train Loss: 1.9664, Train Accuracy: 0.5377 | Test Loss: 2.0603, Test Accuracy: 0.4118\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 5.9995, Test Accuracy: 0.1190\n",
      "Epoch 10/20 => Train Loss: 1.9995, Train Accuracy: 0.4923 | Test Loss: 2.3917, Test Accuracy: 0.4078\n",
      "Epoch 20/20 => Train Loss: 2.6747, Train Accuracy: 0.5099 | Test Loss: 4.0800, Test Accuracy: 0.4810\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 4, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 5.6711, Test Accuracy: 0.1869\n",
      "Epoch 10/20 => Train Loss: 2.1354, Train Accuracy: 0.4875 | Test Loss: 2.2119, Test Accuracy: 0.4196\n",
      "Epoch 20/20 => Train Loss: 2.0581, Train Accuracy: 0.5156 | Test Loss: 2.3451, Test Accuracy: 0.4052\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 6.8809, Test Accuracy: 0.0954\n",
      "Epoch 10/20 => Train Loss: 1.9515, Train Accuracy: 0.4711 | Test Loss: 2.0797, Test Accuracy: 0.4052\n",
      "Epoch 20/20 => Train Loss: 1.7382, Train Accuracy: 0.5456 | Test Loss: 1.8822, Test Accuracy: 0.4523\n",
      "Gen 14: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 32\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 8.0367, Test Accuracy: 0.0837\n",
      "Epoch 10/20 => Train Loss: 1.7511, Train Accuracy: 0.5257 | Test Loss: 1.8934, Test Accuracy: 0.4209\n",
      "Epoch 20/20 => Train Loss: 1.7184, Train Accuracy: 0.5207 | Test Loss: 1.8756, Test Accuracy: 0.4196\n",
      "Gen 15: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 16, 128]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 5.1641, Test Accuracy: 0.1490\n",
      "Epoch 10/20 => Train Loss: 1.8396, Train Accuracy: 0.5484 | Test Loss: 2.0577, Test Accuracy: 0.4065\n",
      "Epoch 20/20 => Train Loss: 2.0130, Train Accuracy: 0.4841 | Test Loss: 2.0883, Test Accuracy: 0.3908\n",
      "Gen 16: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 16, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 6.5550, Test Accuracy: 0.1111\n",
      "Epoch 10/20 => Train Loss: 2.0105, Train Accuracy: 0.4986 | Test Loss: 2.4206, Test Accuracy: 0.3948\n",
      "Epoch 20/20 => Train Loss: 1.9217, Train Accuracy: 0.5163 | Test Loss: 2.4502, Test Accuracy: 0.4039\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 4, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 32\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 8.4953, Test Accuracy: 0.0902\n",
      "Epoch 10/20 => Train Loss: 1.7576, Train Accuracy: 0.4860 | Test Loss: 1.9501, Test Accuracy: 0.3765\n",
      "Epoch 20/20 => Train Loss: 1.7452, Train Accuracy: 0.5175 | Test Loss: 2.2219, Test Accuracy: 0.4052\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 4, 16, 0]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 2.3495, Test Accuracy: 0.0758\n",
      "Epoch 10/20 => Train Loss: 1.9845, Train Accuracy: 0.5462 | Test Loss: 2.0889, Test Accuracy: 0.4144\n",
      "Epoch 20/20 => Train Loss: 1.9665, Train Accuracy: 0.5570 | Test Loss: 2.0597, Test Accuracy: 0.4418\n",
      "Gen 17: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_add_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 1e-05\n",
      "Epoch 0/20 => Test Loss: 1940.2218, Test Accuracy: 0.1072\n",
      "Epoch 10/20 => Train Loss: 853.2074, Train Accuracy: 0.1830 | Test Loss: 565.5688, Test Accuracy: 0.1124\n",
      "Epoch 20/20 => Train Loss: 264.1887, Train Accuracy: 0.1748 | Test Loss: 275.6644, Test Accuracy: 0.1490\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 16, 4]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 7.2198, Test Accuracy: 0.1046\n",
      "Epoch 10/20 => Train Loss: 2.2028, Train Accuracy: 0.4036 | Test Loss: 2.1477, Test Accuracy: 0.3294\n",
      "Epoch 20/20 => Train Loss: 1.8304, Train Accuracy: 0.4812 | Test Loss: 2.0569, Test Accuracy: 0.3895\n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 32, 16, 0]\n",
      "Activation Function: relu\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 5.8931, Test Accuracy: 0.1098\n",
      "Epoch 10/20 => Train Loss: 2.4030, Train Accuracy: 0.4888 | Test Loss: 2.4739, Test Accuracy: 0.3490\n",
      "Epoch 20/20 => Train Loss: 1.9381, Train Accuracy: 0.5137 | Test Loss: 2.2127, Test Accuracy: 0.3739\n",
      "Gen 18: \n",
      "Gen 19: \n",
      "Layer Type: GCNConv\n",
      "Hidden Dimensions: [0, 8, 16, 0]\n",
      "Activation Function: sigmoid\n",
      "Pooling Function: global_mean_pool\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Weight Decay: 0.001\n",
      "Epoch 0/20 => Test Loss: 2.3216, Test Accuracy: 0.0784\n",
      "Epoch 10/20 => Train Loss: 1.9868, Train Accuracy: 0.5229 | Test Loss: 2.0680, Test Accuracy: 0.3856\n",
      "Epoch 20/20 => Train Loss: 1.9725, Train Accuracy: 0.5317 | Test Loss: 2.0505, Test Accuracy: 0.4039\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 20 with tournament_ranked_based_selection and binary_tournament\n",
      "1. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n",
      "2. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n",
      "3. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n",
      "4. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n",
      "5. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n",
      "6. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n",
      "7. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n",
      "8. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n",
      "9. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n",
      "10. Path = [0, 0, 2, 3, 0, 0, 1, 2, 4, 2], Score = 0.4810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tournament_ranked_based_selection + binary_tournament',\n",
       " [0.4470588235294118,\n",
       "  0.4470588235294118,\n",
       "  0.4470588235294118,\n",
       "  0.4470588235294118,\n",
       "  0.4470588235294118,\n",
       "  0.4470588235294118,\n",
       "  0.4470588235294118,\n",
       "  0.44836601307189544,\n",
       "  0.4627450980392157,\n",
       "  0.4627450980392157,\n",
       "  0.4627450980392157,\n",
       "  0.4627450980392157,\n",
       "  0.465359477124183,\n",
       "  0.465359477124183,\n",
       "  0.48104575163398694,\n",
       "  0.48104575163398694,\n",
       "  0.48104575163398694,\n",
       "  0.48104575163398694,\n",
       "  0.48104575163398694,\n",
       "  0.48104575163398694,\n",
       "  0.48104575163398694],\n",
       " [0.26705882352941174,\n",
       "  0.36888888888888893,\n",
       "  0.3881045751633987,\n",
       "  0.40509803921568627,\n",
       "  0.42261437908496735,\n",
       "  0.4470588235294118,\n",
       "  0.4470588235294118,\n",
       "  0.44718954248366016,\n",
       "  0.44862745098039214,\n",
       "  0.44862745098039214,\n",
       "  0.45098039215686275,\n",
       "  0.4525490196078431,\n",
       "  0.4583006535947713,\n",
       "  0.46039215686274515,\n",
       "  0.4650980392156863,\n",
       "  0.46954248366013074,\n",
       "  0.4776470588235294,\n",
       "  0.4771241830065359,\n",
       "  0.4810457516339869,\n",
       "  0.4810457516339869,\n",
       "  0.4810457516339869])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_algorithm_n_gens(persons, fitness_function=fitness_function, n_gens=20, parent_selection_function=tournament_ranked_based_selection, survival_function=binary_tournament)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
